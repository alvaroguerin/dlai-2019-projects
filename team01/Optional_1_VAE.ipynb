{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_AutoEncoder.ipyn",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KEk5hu7BrSr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## **Optional exercise number 1: Variational Autoenconder**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTT8RASHysZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#We'll make it reproducible by using this seed\n",
        "np.random.seed(1)\n",
        "import torch\n",
        "torch.manual_seed(1)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(1)\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ0AcUUVE49H",
        "colab_type": "text"
      },
      "source": [
        "### Load the MNIST datasets into DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BamL_wBRzAgn",
        "colab_type": "code",
        "outputId": "10839992-4e23-4abb-9305-2e4bb97cc6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "hparams = {\n",
        "    'batch_size':64,\n",
        "    'learning_rate':1e-3,\n",
        "    'test_batch_size':64\n",
        "}\n",
        "\n",
        "mnist_trainset = datasets.MNIST('data', train=True, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                ]))\n",
        "mnist_testset = datasets.MNIST('data', train=False, \n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.1307,), (0.3081,))\n",
        "                               ]))\n",
        "\n",
        "\n",
        "# The argument \"drop_last=True\" is given in order to ensure that there won't be a last batch that is not full\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset,\n",
        "                                            batch_size=hparams['batch_size'], \n",
        "                                            shuffle=True,drop_last=True) #Probar si peta sin el drop_last pero no es prioritario\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset,\n",
        "                                          batch_size=hparams['test_batch_size'], \n",
        "                                          shuffle=False,drop_last=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 10547448.76it/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 136732.86it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2469374.04it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 53823.08it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geOzlhtIDWzE",
        "colab_type": "text"
      },
      "source": [
        "# Definition of the network\n",
        "The VAE will be a combination of an Encoder + Decoder with the use of the parametrization trick in between them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz5vJtcyRVCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "   ''' \n",
        "   This the encoder part of the VAE\n",
        "   '''\n",
        "   def __init__(self, bottleneck):\n",
        "     super().__init__()\n",
        "\n",
        "     self.conv1 = nn.Conv2d(1,32,3,padding=1)\n",
        "     self.pool  = nn.MaxPool2d(2,2)\n",
        "     self.conv2 = nn.Conv2d(32,16,3,padding=1)\n",
        "     self.conv3 = nn.Conv2d(16,8,3,padding=1)\n",
        "     self.fc      = nn.Linear(8*7*7, bottleneck)\n",
        "     self.media = nn.Linear(bottleneck,bottleneck)\n",
        "     self.logvar  = nn.Linear(bottleneck,bottleneck)\n",
        "\n",
        "   def forward(self,x):\n",
        "      ## encode ##\n",
        "\n",
        "\n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = self.pool(x)\n",
        "      x = F.relu(self.conv2(x))\n",
        "      x = self.pool(x)\n",
        "      x = F.relu(self.conv3(x))\n",
        "      x = x.view(-1, 8*7*7)\n",
        "      x = F.relu(self.fc(x))\n",
        "      z_media = self.media(x)\n",
        "      logvar   = self.logvar(x)\n",
        "\n",
        "      return z_media, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "   ''' \n",
        "   This the decoder part of the VAE\n",
        "   '''\n",
        "\n",
        "   def __init__(self, bottleneck):\n",
        "     super().__init__()\n",
        "\n",
        "     ## decoder layers ##\n",
        "     ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
        "     self.linear = nn.Linear(bottleneck, 8*7*7)\n",
        "     self.t_conv1 = nn.ConvTranspose2d(8, 16, 2, stride=2)\n",
        "     self.t_conv2 = nn.ConvTranspose2d(16, 32, 2, stride=2)\n",
        "     self.t_conv3 = nn.ConvTranspose2d(32,1,1)\n",
        "\n",
        "   def forward(self,x):\n",
        "     ## decode ##\n",
        "     x = F.relu(self.linear(x))\n",
        "     x = x.view(-1, 8, 7, 7)\n",
        "     x = F.relu(self.t_conv1(x))\n",
        "     # output layer (with sigmoid for scaling from 0 to 1)\n",
        "     x = F.relu(self.t_conv2(x))\n",
        "     x = torch.sigmoid(self.t_conv3(x))\n",
        "            \n",
        "     return x\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  '''\n",
        "  This takes both encoder and decoder into the same network\n",
        "  '''\n",
        "  def __init__(self, enc, dec):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = enc\n",
        "    self.decoder = dec\n",
        "\n",
        "  def forward(self,x):\n",
        "    #encode\n",
        "    z_media,logvar = self.encoder(x)\n",
        "  \n",
        "    # Reparametrization trick\n",
        "    std = torch.exp(0.5*logvar)\n",
        "    # Standard Gaussian with correct size\n",
        "    eps = torch.randn_like(std)\n",
        "    # This allows for the gradients to flow\n",
        "    x_sample = z_media + eps*std\n",
        " \n",
        "    #Decode\n",
        "    predicted = self.decoder(x_sample)\n",
        "\n",
        "    return predicted,z_media,logvar\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfR6Jm2VQN0L",
        "colab_type": "text"
      },
      "source": [
        "# Now we have to train the network for a number of epochs\n",
        "In order to make this in a propper manner we define a train() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-ayutM1QYyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lossFunction(data,z_mu,logvar,prediction):\n",
        "    # Reconstruction loss\n",
        "    recon_loss = F.binary_cross_entropy(prediction, data, reduction='sum')\n",
        "    # KL divergence loss\n",
        "    kld = -0.5 * torch.sum(1+logvar - z_mu.pow(2) - logvar.exp()) * 600 #This 600 is the disentangle parameter.\n",
        "\n",
        "    # total loss\n",
        "    loss = recon_loss + kld\n",
        "    return loss, recon_loss, kld\n",
        "\n",
        "\n",
        "def train(model, num_epochs):\n",
        "  # Prepare the GPU and the model to start training\n",
        "  model.train()\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr = hparams['learning_rate']) # learning rate chosen at random\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    # For tracking the loss of the model\n",
        "    closs = 0\n",
        "    crl, ckdl = 0, 0\n",
        "    for batch_idx, (data,_) in enumerate(train_loader):\n",
        "      # Put data and label into GPU\n",
        "      data = data.to(device)\n",
        "      \n",
        "      # What does the model say \n",
        "      prediction, z_mu,logvar = model(data)\n",
        "      loss, rl, kdl = lossFunction(data,z_mu,logvar,prediction)\n",
        "      closs += loss.item() \n",
        "      crl += rl\n",
        "      ckdl += kdl\n",
        "      # Name a more iconic trio\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    print('Epoch: {} \\tRecon Loss: {:.6f}\\tKDL Loss: {:.6f}'.format(epoch+1,crl/len(mnist_trainset), ckdl/len(mnist_trainset)))  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCOV0afqSzJx",
        "colab_type": "code",
        "outputId": "cc973f2e-9b7a-4cfc-c179-a2b83be8dcb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "BotNeck = 20\n",
        "\n",
        "encoder = Encoder(BotNeck)\n",
        "decoder = Decoder(BotNeck)\n",
        "model = VAE(encoder,decoder)\n",
        "\n",
        "\n",
        "train(model,30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tRecon Loss: -8084.705078\tKDL Loss: 50.886410\n",
            "Epoch: 2 \tRecon Loss: -9166.176758\tKDL Loss: 65.162643\n",
            "Epoch: 3 \tRecon Loss: -7863.810059\tKDL Loss: 66.644249\n",
            "Epoch: 4 \tRecon Loss: -7294.259277\tKDL Loss: 68.521111\n",
            "Epoch: 5 \tRecon Loss: -6910.531250\tKDL Loss: 77.971512\n",
            "Epoch: 6 \tRecon Loss: -6316.003906\tKDL Loss: 104.015381\n",
            "Epoch: 7 \tRecon Loss: -6033.281738\tKDL Loss: 164.924164\n",
            "Epoch: 8 \tRecon Loss: -6002.853027\tKDL Loss: 233.169952\n",
            "Epoch: 9 \tRecon Loss: -5967.974121\tKDL Loss: 267.618011\n",
            "Epoch: 10 \tRecon Loss: -5922.564941\tKDL Loss: 289.501892\n",
            "Epoch: 11 \tRecon Loss: -5906.636230\tKDL Loss: 296.553345\n",
            "Epoch: 12 \tRecon Loss: -5895.642090\tKDL Loss: 310.707397\n",
            "Epoch: 13 \tRecon Loss: -5886.431641\tKDL Loss: 316.706268\n",
            "Epoch: 14 \tRecon Loss: -5889.387695\tKDL Loss: 330.988251\n",
            "Epoch: 15 \tRecon Loss: -5906.155273\tKDL Loss: 336.085297\n",
            "Epoch: 16 \tRecon Loss: -5909.641113\tKDL Loss: 343.030975\n",
            "Epoch: 17 \tRecon Loss: -5918.229004\tKDL Loss: 348.876556\n",
            "Epoch: 18 \tRecon Loss: -5914.995117\tKDL Loss: 348.526459\n",
            "Epoch: 19 \tRecon Loss: -5921.413086\tKDL Loss: 354.575256\n",
            "Epoch: 20 \tRecon Loss: -5926.694336\tKDL Loss: 361.784271\n",
            "Epoch: 21 \tRecon Loss: -5935.566895\tKDL Loss: 370.030090\n",
            "Epoch: 22 \tRecon Loss: -5953.841309\tKDL Loss: 377.861359\n",
            "Epoch: 23 \tRecon Loss: -5971.791992\tKDL Loss: 391.531097\n",
            "Epoch: 24 \tRecon Loss: -5988.060547\tKDL Loss: 405.869537\n",
            "Epoch: 25 \tRecon Loss: -6017.891602\tKDL Loss: 426.711609\n",
            "Epoch: 26 \tRecon Loss: -6038.128418\tKDL Loss: 444.635529\n",
            "Epoch: 27 \tRecon Loss: -6060.587402\tKDL Loss: 451.433807\n",
            "Epoch: 28 \tRecon Loss: -6070.220215\tKDL Loss: 459.623413\n",
            "Epoch: 29 \tRecon Loss: -6073.396484\tKDL Loss: 470.887299\n",
            "Epoch: 30 \tRecon Loss: -6088.249512\tKDL Loss: 472.325714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR4sbW1mRaXC",
        "colab_type": "code",
        "outputId": "bd94d6b0-2d75-4816-b087-5c34e3e9d6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "# sample and generate a image\n",
        "z = torch.randn(1, BotNeck)\n",
        "model.to(\"cpu\")\n",
        "# run only the decoder\n",
        "reconstructed_img = model.decoder(z)\n",
        "\n",
        "# Go home and run this.\n",
        "print(z.shape)\n",
        "print(reconstructed_img.detach().squeeze().shape)\n",
        "\n",
        "plt.imshow(reconstructed_img.detach().squeeze().numpy(), cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 20])\n",
            "torch.Size([28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4c796c1ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s58E-oUov-XP",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the model can't form digits very well. It is fairly simple to see that they look similar to the MNIST dataset but the result is still pretty clumsy. We use 600 as the disentangle hyperparameter."
      ]
    }
  ]
}