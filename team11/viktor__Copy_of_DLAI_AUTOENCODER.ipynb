{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "viktor_ Copy of DLAI_AUTOENCODER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkyWHeD9C5mJ",
        "colab_type": "text"
      },
      "source": [
        "Library Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nUj4_z0CupF",
        "colab_type": "code",
        "outputId": "e196f42f-8480-4939-cdca-9eb742e43ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# load the training and test datasets\n",
        "train_data = datasets.MNIST(root='data', train=True,download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False,download=True, transform=transform)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9501996.82it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 135694.87it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2303267.02it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51066.65it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ugFSg8cJYAx",
        "colab_type": "text"
      },
      "source": [
        "Splitting The Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNvx8BkVJaXH",
        "colab_type": "code",
        "outputId": "3c8893b6-8ab3-49a4-faf2-75eb9511d466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "validation_size = int(0.05*len(train_data))\n",
        "training_size = int(0.95*len(train_data))\n",
        "\n",
        "train_dataset, validation_dataset = torch.utils.data.random_split(train_data, [training_size, validation_size])\n",
        "\n",
        "print(len(validation_dataset))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzJFXUBaDFhQ",
        "colab_type": "text"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2zRoJUGC_KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElduB3PHDHvL",
        "colab_type": "text"
      },
      "source": [
        "Visualize Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_TYk7f_UWzb",
        "colab_type": "text"
      },
      "source": [
        "Encoder & Decoder in Different Modules with bottleneck value passed in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTzyLyxoUaHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "   def __init__(self,bottleneck):\n",
        "     super().__init__()\n",
        "\n",
        "     self.conv1 = nn.Conv2d(1,16,3,padding=1)\n",
        "     self.conv2 = nn.Conv2d(16,bottleneck,3,padding=1)\n",
        "     self.pool  = nn.MaxPool2d(2,2)\n",
        "\n",
        "   def forward(self,x):\n",
        "        ## encode ##\n",
        "        # add hidden layers with relu activation function\n",
        "        # and maxpooling after\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        # add second hidden layer\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)  # compressed representation\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "   def __init__(self,bottleneck):\n",
        "     super().__init__()\n",
        "\n",
        "     ## decoder layers ##\n",
        "     ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
        "     self.t_conv1 = nn.ConvTranspose2d(bottleneck, 16, 2, stride=2)\n",
        "     self.t_conv2 = nn.ConvTranspose2d(16, 1, 2, stride=2)\n",
        "     \n",
        "       \n",
        "\n",
        "   def forward(self,x):\n",
        "     ## decode ##\n",
        "     # add transpose conv layers, with relu activation function\n",
        "     x = F.relu(self.t_conv1(x))\n",
        "     # output layer (with sigmoid for scaling from 0 to 1)\n",
        "     x = F.sigmoid(self.t_conv2(x))\n",
        "            \n",
        "     return x\n",
        "\n",
        "class Concatenator(nn.Module):\n",
        "\n",
        "  def __init__(self, enc, dec):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = enc\n",
        "    self.decoder = dec\n",
        "\n",
        "  def forward(self,x):\n",
        "    #encode\n",
        "    x = self.encoder(x)\n",
        "    y = self.decoder(x)\n",
        "\n",
        "    return y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r_NUGcuDaI-",
        "colab_type": "text"
      },
      "source": [
        "Training           have not done for different bottlenecks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqeTP8_6Da_q",
        "colab_type": "code",
        "outputId": "2e522b3a-ae80-401f-9fef-f181ba414fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "# Loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "encoder = Encoder(3)\n",
        "decoder = Decoder(3)\n",
        "model = Concatenator(encoder,decoder)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "train_losses, val_losses = [], []\n",
        "epochs = 3\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    train_loss = 0.0  # monitor training loss\n",
        "    validation_loss = 0.0 \n",
        "    for data in train_loader:\n",
        "     \n",
        "      images, _ = data                        # we are just intrested in just images\n",
        "      # no need to flatten images\n",
        "      optimizer.zero_grad()                   # clear the gradients\n",
        "      outputs = model(images)                 # forward pass: compute predicted outputs \n",
        "      loss = criterion(outputs, images)       # calculate the loss\n",
        "      loss.backward()                         # backward pass\n",
        "      optimizer.step()                        # perform optimization step\n",
        "      train_loss += loss.item()*images.size(0)# update running training loss\n",
        "\n",
        "    for data in validation_loader:\n",
        "      model.eval()\n",
        "      images, _ = data                        # we are just intrested in just images\n",
        "      #no need to flatten images\n",
        "      outputs = model(images)                 # forward pass: compute predicted outputs \n",
        "      loss = criterion(outputs, images)       # calculate the loss\n",
        "      validation_loss += loss.item()*images.size(0)# update running training loss\n",
        "        \n",
        "    # print avg training statistics \n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    print('Epoch: {}'.format(e),\n",
        "              '\\tTraining Loss: {:.4f}'.format(train_loss))\n",
        "    validation_loss = validation_loss/len(validation_loader)\n",
        "    print('Epoch: {}'.format(e),\n",
        "              '\\tValidation Loss: {:.4f}'.format(validation_loss))\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(validation_loss)    \n",
        "   #bottleneck = bottleneck +3\n",
        "   #print (bottlneck)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.8654\n",
            "Epoch: 1 \tValidation Loss: 0.5907\n",
            "Epoch: 2 \tTraining Loss: 0.5609\n",
            "Epoch: 2 \tValidation Loss: 0.5210\n",
            "Epoch: 3 \tTraining Loss: 0.4789\n",
            "Epoch: 3 \tValidation Loss: 0.4547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31D0p7Too7JS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "plot val and train loss       plot for diff bottlenecks       "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zILV6J3o_nB",
        "colab_type": "code",
        "outputId": "cb60eb44-35ec-4d14-c368-4fba86c25a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(val_losses, label='val')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc605413898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxHxCQW6iIhPKNBFRHzi/wOASAdlWd2ZpQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F44JkEsgc5C",
        "colab_type": "text"
      },
      "source": [
        "Test Loss           compute for validation as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNBZHdNegeFt",
        "colab_type": "code",
        "outputId": "9abbd023-a463-40eb-9c2c-993aa6144ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "test_loss=0.0\n",
        "for data in test_loader:\n",
        "  images, _ = data                        # we are just intrested in just images\n",
        "  # no need to flatten images\n",
        "  optimizer.zero_grad()                   # clear the gradients\n",
        "  outputs = model(images)                 # forward pass: compute predicted outputs \n",
        "  loss = criterion(outputs, images)       # calculate the loss\n",
        "  test_loss += loss.item()*images.size(0)\n",
        "        \n",
        "test_loss = test_loss/len(test_loader)\n",
        "print(test_loss)\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(pytorch_total_params)\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.45185260772705077\n",
            "868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87pI_tLJyxE6",
        "colab_type": "text"
      },
      "source": [
        "5.                              for model with some bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHPgTdeIywME",
        "colab_type": "code",
        "outputId": "a6d1457f-0f19-4ab1-ff1c-3ceb6dfc1964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "# Lets get batch of test images\n",
        "\n",
        "import random\n",
        "dataiter = iter(test_loader)\n",
        "\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "\n",
        "\n",
        "output = model(images)                     # get sample outputs\n",
        "images = images.numpy() \n",
        "\n",
        "\n",
        "                  # prep images for display\n",
        "output = output.view(batch_size, 1, 28, 28)# resizing output\n",
        "output = output.detach().numpy()           # use detach when it's an output that requires_grad\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True, figsize=(25,4))\n",
        "# input images on top row, reconstructions on bottom\n",
        "for images, row in zip([images, output], axes):\n",
        "    for img, ax in zip(images, row):\n",
        "        ax.imshow(np.squeeze(img), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABPcAAADrCAYAAAAFQXMxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEBM/T9yRbrDSNdGugAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1800x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHJJBhTMzCzs",
        "colab_type": "text"
      },
      "source": [
        "6. Generate 5 new images by injecting random values as input to the decoder. Show them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_w1mLpzDit",
        "colab_type": "code",
        "outputId": "6af6119e-a77b-476a-f565-8a8c96a4927f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        }
      },
      "source": [
        "input = torch.rand(6,3,28,28)\n",
        "#output = decoder(input)\n",
        "output = output.detach().numpy()\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True, figsize=(25,4))\n",
        "\n",
        "for i in range(5):\n",
        "  axes[0][i].imshow(np.squeeze(input[i]),cmap = 'gray')\n",
        "  axes[1][i].imshow(np.squeeze(input[i]),cmap = 'gray')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-bfcdefd759c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 28, 28) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABaYAAAD8CAYAAACMynOkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1800x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHL5xdA0Z9yY",
        "colab_type": "text"
      },
      "source": [
        "Excersice 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akjWNJPdRAr_",
        "colab_type": "text"
      },
      "source": [
        "Select subset of 100 images & labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeRwhhz-aACs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset  = torch.utils.data.Subset(train_dataset, range(0, 100))\n",
        "len(subset)\n",
        "subset_loader = torch.utils.data.DataLoader(subset, batch_size=batch_size, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O19D00rUc2Cy",
        "colab_type": "text"
      },
      "source": [
        "select one of the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AjRTGvOc4W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = Encoder(3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX-z93i1Rc8P",
        "colab_type": "text"
      },
      "source": [
        "create the classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLPUbOa-oAOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_classifier =    nn.Sequential( nn.Linear(3*7*7,10),\n",
        "                      nn.LogSoftmax(-1)\n",
        "                      )\n",
        "\n",
        "#model_2 = nn.Sequential(encoder,\n",
        " #                       nn.Flatten(),\n",
        "  #                      nn.Linear(3*7*7,10),\n",
        "    #                    nn.LogSoftmax(-1)\n",
        "   #                     )\n",
        "\n",
        "model_2 = nn.Sequential(encoder,\n",
        "                        nn.Flatten(),\n",
        "                        model_classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6_FZcH7e3GH",
        "colab_type": "text"
      },
      "source": [
        "Train the classifer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpJlkh9te4jT",
        "colab_type": "code",
        "outputId": "8b9e8c0f-f6c0-4b67-e8b3-637da6ccf813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "criterion = F.nll_loss\n",
        "\n",
        "# Optimizer\n",
        "#optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.RMSprop(model_2.parameters(), lr=0.001)\n",
        "train_losses, val_losses = [],[]\n",
        "epochs = 10\n",
        "model_2.train()\n",
        "for e in range(1, epochs+1):\n",
        "    train_loss = 0.0  # monitor training loss\n",
        "    for data in subset_loader:\n",
        "     \n",
        "      images, labels = data                        # we are just intrested in just images & labels\n",
        "      optimizer.zero_grad()                        # clear the gradients\n",
        "      outputs = model_2(images)                    # forward pass: compute predicted outputs \n",
        "      loss = criterion(outputs, labels)           # calculate the loss\n",
        "      loss.backward()                             # backward pass\n",
        "      optimizer.step()                             # perform optimization step\n",
        "      train_loss += loss.item()*images.size(0)     # update running training loss\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      print('Epoch: {}'.format(e),\n",
        "              '\\tTraining Loss: {:.4f}'.format(train_loss))\n",
        "      train_losses.append(train_loss)\n",
        "   #bottleneck = bottleneck +3\n",
        "   #print (bottlneck)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.0031\n",
            "Epoch: 1 \tTraining Loss: 0.0330\n",
            "Epoch: 1 \tTraining Loss: 0.0127\n",
            "Epoch: 1 \tTraining Loss: 0.0032\n",
            "Epoch: 1 \tTraining Loss: 0.0044\n",
            "Epoch: 2 \tTraining Loss: 0.0031\n",
            "Epoch: 2 \tTraining Loss: 0.0053\n",
            "Epoch: 2 \tTraining Loss: 0.0038\n",
            "Epoch: 2 \tTraining Loss: 0.0027\n",
            "Epoch: 2 \tTraining Loss: 0.0033\n",
            "Epoch: 3 \tTraining Loss: 0.0027\n",
            "Epoch: 3 \tTraining Loss: 0.0043\n",
            "Epoch: 3 \tTraining Loss: 0.0031\n",
            "Epoch: 3 \tTraining Loss: 0.0022\n",
            "Epoch: 3 \tTraining Loss: 0.0027\n",
            "Epoch: 4 \tTraining Loss: 0.0024\n",
            "Epoch: 4 \tTraining Loss: 0.0038\n",
            "Epoch: 4 \tTraining Loss: 0.0027\n",
            "Epoch: 4 \tTraining Loss: 0.0019\n",
            "Epoch: 4 \tTraining Loss: 0.0023\n",
            "Epoch: 5 \tTraining Loss: 0.0022\n",
            "Epoch: 5 \tTraining Loss: 0.0034\n",
            "Epoch: 5 \tTraining Loss: 0.0024\n",
            "Epoch: 5 \tTraining Loss: 0.0017\n",
            "Epoch: 5 \tTraining Loss: 0.0020\n",
            "Epoch: 6 \tTraining Loss: 0.0020\n",
            "Epoch: 6 \tTraining Loss: 0.0030\n",
            "Epoch: 6 \tTraining Loss: 0.0022\n",
            "Epoch: 6 \tTraining Loss: 0.0016\n",
            "Epoch: 6 \tTraining Loss: 0.0018\n",
            "Epoch: 7 \tTraining Loss: 0.0018\n",
            "Epoch: 7 \tTraining Loss: 0.0028\n",
            "Epoch: 7 \tTraining Loss: 0.0020\n",
            "Epoch: 7 \tTraining Loss: 0.0015\n",
            "Epoch: 7 \tTraining Loss: 0.0016\n",
            "Epoch: 8 \tTraining Loss: 0.0017\n",
            "Epoch: 8 \tTraining Loss: 0.0025\n",
            "Epoch: 8 \tTraining Loss: 0.0018\n",
            "Epoch: 8 \tTraining Loss: 0.0014\n",
            "Epoch: 8 \tTraining Loss: 0.0015\n",
            "Epoch: 9 \tTraining Loss: 0.0015\n",
            "Epoch: 9 \tTraining Loss: 0.0023\n",
            "Epoch: 9 \tTraining Loss: 0.0017\n",
            "Epoch: 9 \tTraining Loss: 0.0014\n",
            "Epoch: 9 \tTraining Loss: 0.0013\n",
            "Epoch: 10 \tTraining Loss: 0.0014\n",
            "Epoch: 10 \tTraining Loss: 0.0021\n",
            "Epoch: 10 \tTraining Loss: 0.0015\n",
            "Epoch: 10 \tTraining Loss: 0.0013\n",
            "Epoch: 10 \tTraining Loss: 0.0012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LTQ8ezsmO2S",
        "colab_type": "text"
      },
      "source": [
        "5. Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmGv7kb5mQoM",
        "colab_type": "code",
        "outputId": "2010e68f-1dfe-4fc0-e8ce-f28e3a948991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "criterion = F.nll_loss\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(encoder.parameters(), lr=0.00000001)\n",
        "optimizer1 = torch.optim.Adam(model_classifier.parameters(), lr=0.001)\n",
        "#optimizer = torch.optim.RMSprop(model_2.parameters(), lr=0.001)\n",
        "\n",
        "train_losses, val_losses = [],[]\n",
        "epochs = 10\n",
        "model_2.train()\n",
        "for e in range(1, epochs+1):\n",
        "    train_loss = 0.0  # monitor training loss\n",
        "    for data in subset_loader:\n",
        "     \n",
        "      images, labels = data                        # we are just intrested in just images & labels\n",
        "      optimizer.zero_grad()                        # clear the gradients\n",
        "      optimizer1.zero_grad()                        # clear the gradients\n",
        "      outputs = model_2(images)                    # forward pass: compute predicted outputs \n",
        "      loss = criterion(outputs, labels)           # calculate the loss\n",
        "      loss.backward()                             # backward pass\n",
        "      optimizer.step()                             # perform optimization step\n",
        "      optimizer1.step()\n",
        "      train_loss += loss.item()*images.size(0)     # update running training loss\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      print('Epoch: {}'.format(e),\n",
        "              '\\tTraining Loss: {:.4f}'.format(train_loss))\n",
        "      train_losses.append(train_loss)\n",
        "   #bottleneck = bottleneck +3\n",
        "   #print (bottlneck)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.0005\n",
            "Epoch: 1 \tTraining Loss: 0.0014\n",
            "Epoch: 1 \tTraining Loss: 0.0010\n",
            "Epoch: 1 \tTraining Loss: 0.0009\n",
            "Epoch: 1 \tTraining Loss: 0.0014\n",
            "Epoch: 2 \tTraining Loss: 0.0005\n",
            "Epoch: 2 \tTraining Loss: 0.0012\n",
            "Epoch: 2 \tTraining Loss: 0.0013\n",
            "Epoch: 2 \tTraining Loss: 0.0005\n",
            "Epoch: 2 \tTraining Loss: 0.0007\n",
            "Epoch: 3 \tTraining Loss: 0.0007\n",
            "Epoch: 3 \tTraining Loss: 0.0013\n",
            "Epoch: 3 \tTraining Loss: 0.0011\n",
            "Epoch: 3 \tTraining Loss: 0.0005\n",
            "Epoch: 3 \tTraining Loss: 0.0009\n",
            "Epoch: 4 \tTraining Loss: 0.0005\n",
            "Epoch: 4 \tTraining Loss: 0.0011\n",
            "Epoch: 4 \tTraining Loss: 0.0008\n",
            "Epoch: 4 \tTraining Loss: 0.0006\n",
            "Epoch: 4 \tTraining Loss: 0.0011\n",
            "Epoch: 5 \tTraining Loss: 0.0004\n",
            "Epoch: 5 \tTraining Loss: 0.0010\n",
            "Epoch: 5 \tTraining Loss: 0.0008\n",
            "Epoch: 5 \tTraining Loss: 0.0006\n",
            "Epoch: 5 \tTraining Loss: 0.0009\n",
            "Epoch: 6 \tTraining Loss: 0.0004\n",
            "Epoch: 6 \tTraining Loss: 0.0010\n",
            "Epoch: 6 \tTraining Loss: 0.0009\n",
            "Epoch: 6 \tTraining Loss: 0.0005\n",
            "Epoch: 6 \tTraining Loss: 0.0007\n",
            "Epoch: 7 \tTraining Loss: 0.0004\n",
            "Epoch: 7 \tTraining Loss: 0.0010\n",
            "Epoch: 7 \tTraining Loss: 0.0009\n",
            "Epoch: 7 \tTraining Loss: 0.0004\n",
            "Epoch: 7 \tTraining Loss: 0.0007\n",
            "Epoch: 8 \tTraining Loss: 0.0004\n",
            "Epoch: 8 \tTraining Loss: 0.0009\n",
            "Epoch: 8 \tTraining Loss: 0.0008\n",
            "Epoch: 8 \tTraining Loss: 0.0005\n",
            "Epoch: 8 \tTraining Loss: 0.0008\n",
            "Epoch: 9 \tTraining Loss: 0.0004\n",
            "Epoch: 9 \tTraining Loss: 0.0009\n",
            "Epoch: 9 \tTraining Loss: 0.0007\n",
            "Epoch: 9 \tTraining Loss: 0.0005\n",
            "Epoch: 9 \tTraining Loss: 0.0007\n",
            "Epoch: 10 \tTraining Loss: 0.0004\n",
            "Epoch: 10 \tTraining Loss: 0.0009\n",
            "Epoch: 10 \tTraining Loss: 0.0007\n",
            "Epoch: 10 \tTraining Loss: 0.0004\n",
            "Epoch: 10 \tTraining Loss: 0.0007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDMd6vwLw00A",
        "colab_type": "text"
      },
      "source": [
        "6. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uacsqo0w7gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}