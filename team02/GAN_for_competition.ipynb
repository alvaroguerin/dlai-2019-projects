{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_for_competition.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qmLNXBJxwzoF","colab_type":"text"},"source":["TODO for competition exercises:\n","\n","For Exercise 1:\n","- Make a function to determine bottleneck size\n","- Make the net more deep, and add a fc layer with bottlnek_size\n","- Add an early stoping parameter\n","- Use Tensorboard to visualize the train steps\n","\n","For Exercise 2:\n","\n","For Optional A:\n","\n","For Optional B:\n","1.   Improve architecture\n","2.   Add a conditional factor to choose the number to generate:\n","- Add an embedding of a one hot encoding of the 10 numbers in the input of the generator and discriminator.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3v7GsJaduH8Q","colab_type":"text"},"source":["# Optional B: Generative Network\n","\n","In this section is designed a vanilla implementation of a Generative Adversarial Network for MNIST number generation.\n","\n","In this case we also add the possibility to conditionate the network with the value to generate.\n"]},{"cell_type":"code","metadata":{"id":"19bEXSP623nt","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import random\n","import logging\n","\n","from torchvision import datasets, transforms\n","from timeit import default_timer as timer\n","from torch.autograd.variable import Variable"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPwNiVyDLIDV","colab_type":"text"},"source":["*Get training dataset, convert to tensors and normalize*"]},{"cell_type":"code","metadata":{"id":"Cgzlscbq3HHH","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RhaYYvV5uJT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"015c1981-9711-4b70-80c7-ce0a542d1450","executionInfo":{"status":"ok","timestamp":1575470763669,"user_tz":-60,"elapsed":8966,"user":{"displayName":"Marti Grau Gasulla","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB9fMvTXDuVkvtOgF8K--sg9b9UhdIvFz2A6q2UvbQ=s64","userId":"03128845478504801773"}}},"source":["mnist_trainset = datasets.MNIST('data', train=True, download=True,\n","                                transform=transforms.Compose([\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize((0.1307,), (0.3081,)) # normalize to mean and std deviation of the MNIST dataset\n","                                ]))\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:06, 1604933.72it/s]                            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 0/28881 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 130508.19it/s]           \n","  0%|          | 0/1648877 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:00, 2362198.10it/s]                           \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 49996.85it/s]            "],"name":"stderr"},{"output_type":"stream","text":["Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6k-7fqjk3DrU","colab_type":"code","colab":{}},"source":["train_loader = torch.utils.data.DataLoader(\n","    mnist_trainset,\n","    batch_size=BATCH_SIZE, \n","    shuffle=True)\n","\n","num_batches = len(train_loader)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uNd8KypU6uVJ","colab_type":"text"},"source":["## Definition of the Generator and Discriminator classes"]},{"cell_type":"markdown","metadata":{"id":"qAElL3H_mzMu","colab_type":"text"},"source":["** Provar altres parÃ metres:\n","- Provar amb LeakyReLU\n","- Afegir dropout\n"]},{"cell_type":"code","metadata":{"id":"QdKcl-Yk3NB5","colab_type":"code","colab":{}},"source":["# Generator class\n","class Generator (nn.Module):\n","    def __init__(self,inp,out):\n","        super(Generator,self).__init__()\n","\n","        self.label_embedding = nn.Embedding(10,10) #num_embedings, embedding_dim (one-hot vector)\n","\n","        self.gen = nn.Sequential(\n","              nn.Linear(inp+10, 256),     #inp = The input of the generator is a lattent vector of 'X' size\n","              nn.LeakyReLU(0.2), \n","              nn.Linear(256,512),\n","              nn.LeakyReLU(0.2),\n","              nn.Linear(512,1024),\n","              nn.LeakyReLU(0.2),\n","              nn.Linear(1024,out),    #out = The output of the generator has to be a vector of 28*28 = 784\n","              nn.Tanh()\n","          )\n","\n","    def forward(self,x, labels):\n","        label = self.label_embedding(labels)\n","        out = torch.cat([x,label], 1)         #Concatenate the image vector x with his respective label one-hot encoded\n","        out = self.gen(out)\n","        return out\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"--lHpeis3RnE","colab_type":"code","colab":{}},"source":["# Discriminator class\n","class Discriminator (nn.Module):\n","    def __init__(self,inp,out):\n","        super(Discriminator,self).__init__()\n","\n","        self.label_embedding = nn.Embedding(10,10) #num_embedings, embedding_dim (one-hot vector)\n","\n","        self.discrim = nn.Sequential(\n","            nn.Linear(inp+10, 1024),     #inp = The input of the dicriminator is a vector of image input (28*28)\n","            nn.LeakyReLU(0.2, inplace = True),\n","            nn.Dropout(0.3),\n","            nn.Linear(1024, 512),\n","            nn.LeakyReLU(0.2, inplace = True),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(0.2, inplace = True),\n","            nn.Dropout(0.3),\n","            nn.Linear(256, out),      #out = This has to be 1 value with prob of Real or Fake\n","            nn.Sigmoid(),             #This activation function will be used to set 0 (fake) or 1 (real)\n","        )\n","\n","    def forward(self,x, labels):\n","        label = self.label_embedding(labels)\n","        out = torch.cat([x,label], 1)         #Concatenate the image vector x with his respective label one-hot encoded\n","        out = self.discrim(out)\n","        return out\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VhwHHCwJ3ZhW","colab_type":"text"},"source":["## Training functions"]},{"cell_type":"markdown","metadata":{"id":"xWdzhuFuXFOh","colab_type":"text"},"source":["We first will define the following hiperparameters:\n"," - Loss: In this case we will Binary Cross Entropy\n"," - Optimizers: Stochastic Gradient dicent with their respective parameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ifHuHDoc93ZQ","colab":{}},"source":["\n","input_size_gen = 100\n","input_size_dis = 784\n","output_size_gen = 784\n","output_size_dis = 1\n","\n","hparams = {\n","    'train_batch_size':BATCH_SIZE,\n","    'num_epochs':200,\n","    'learning_rate':1e-4\n","}\n","\n","# we select to work on GPU if it is available in the machine, otherwise we will run on cpu\n","hparams['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n","if torch.cuda.is_available():\n","  torch.cuda.random_seed(1)\n","\n","# We initializate the gen and disc\n","generator = Generator(input_size_gen, output_size_gen)\n","discriminator = Discriminator(input_size_dis, output_size_dis)\n","\n","# Loss for Generator and Discriminator\n","loss = nn.BCELoss()\n","\n","# Optimizers\n","gen_optimizer   = optim.Adam(generator.parameters(), lr = hparams['learning_rate'])\n","dis_optimizer   = optim.Adam(discriminator.parameters(), lr = hparams['learning_rate'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECACB5IvQb9x","colab_type":"text"},"source":["The following function will be used to plot the generated image while training"]},{"cell_type":"code","metadata":{"id":"FgzanFqdQmDf","colab_type":"code","colab":{}},"source":["def plot_gen_img(array_img, num = None):\n","  array_img   = array_img.detach()\n","  array_img = array_img.squeeze(0)\n","  array_img = array_img.squeeze(0)\n","  plt.imshow(array_img, cmap = 'binary')\n","  plt.xticks([])\n","  plt.yticks([])\n","  if num:\n","      plt.xlabel(num,fontsize='x-large')\n","  plt.show()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-vdHOf_Riw4d","colab_type":"text"},"source":["The following functions will be used to transform the images to vectors or vice versa."]},{"cell_type":"code","metadata":{"id":"3Cl8Zn-P6S5e","colab_type":"code","colab":{}},"source":["def images_to_vectors(images):\n","    return images.view(images.size(0), 784)\n","\n","def vectors_to_images(vectors):\n","    return vectors.view(vectors.size(0), 1, 28, 28)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"efdhPdNI6LfD","colab_type":"text"},"source":["We also need to be able to create some random nosie to introduce to the Generative model with the following function:"]},{"cell_type":"code","metadata":{"id":"V7pW9_zdiOPf","colab_type":"code","colab":{}},"source":["def create_noise(size):\n","    n = Variable(torch.randn(size, 100))\n","    return n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oSuV9Pq-jeBf","colab_type":"text"},"source":["We create 'X' random vectors to create a test input to send it through the generator and check the synthetized output every 'X' batches."]},{"cell_type":"code","metadata":{"id":"XMU7tXgiPWEK","colab_type":"code","colab":{}},"source":["num_test_samples = 1\n","test_noise = create_noise(num_test_samples)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gFmwKOnBc7cR","colab_type":"text"},"source":["Functions to create ground truth labels when real_images or fake_images\n","\n","- Vector of 1's when Real Images\n","- Vector of 0's when Fake Images"]},{"cell_type":"code","metadata":{"id":"uBoakxQVEWBc","colab_type":"code","colab":{}},"source":["def real_target(size):\n","    data = Variable(torch.ones(size, 1)) \n","    return data\n","\n","def fake_target(size):\n","    data = Variable(torch.zeros(size, 1))\n","    return data\n","\n","def fake_labels(size):\n","    data = Variable(torch.LongTensor(np.random.randint(0,10,size))) # Tensor filled with random int generated between low and high\n","    return data\n","\n","def create_label_num(size):\n","    data = Variable(torch.LongTensor(np.arange(size)))\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CKde4OQ48YcV","colab":{}},"source":["def train_discriminator(real_inp, labels, fake_inp, fake_labels, dis_opt, N):\n","    discriminator.train()\n","    device = hparams['device']\n","    # Reset Gradients\n","    dis_opt.zero_grad()\n","\n","    # Train Discriminator with real images\n","    prediction_real  = discriminator.forward(real_inp, labels)          # Send the input through the discriminator model\n","    dis_real_loss = loss(prediction_real, real_target(N))       # As a ground truth we set a vector of 1 (Real)\n","    dis_real_loss.backward()\n","\n","    # Train Discriminator with the image produced by the Generator\n","    prediction_fake  = discriminator(fake_inp, fake_labels)\n","    dis_fake_loss = loss(prediction_fake, fake_target(N)) # As a ground truth we set a vector of 0 (Fake)\n","    dis_fake_loss.backward()\n","\n","    #We Optimize the Discriminator\n","    dis_opt.step()\n","    return dis_real_loss + dis_fake_loss , prediction_real, prediction_fake      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fENho2SA8byE","colab":{}},"source":["def train_generator(fake_inp, gen_opt, N):\n","      generator.train()\n","      device = hparams['device']\n","      # Reset Gradients\n","      gen_opt.zero_grad()\n","      \n","      #Create FAKE labels\n","      fake_lbls = fake_labels(N)\n","      # Send the random input through the Generator\n","      prediction = discriminator(fake_inp, fake_lbls)\n","\n","      # Compute Loss for the Generator\n","      gen_train_loss = loss(prediction, real_target(N)) # As a ground truth we set a vector of 1 (Real) to make the Generator learn\n","      gen_train_loss.backward()\n","\n","\n","      gen_opt.step()\n","      return gen_train_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahHMrVjBY5no","colab_type":"code","colab":{}},"source":["def train_net(train_loader, gen_opt, dis_opt, num_epochs):\n","    gen_losses = []\n","    dis_losses = []\n","    generator.to(hparams['device']) \n","    discriminator.to(hparams['device'])\n","    # train over the number of epochs\n","    for epoch in range(1,num_epochs + 1):\n","        for batch_idx, (real_inp, labels) in enumerate(train_loader):\n","            N = real_inp.size(0) # Batch size == BATCH_SIZE defined above\n","\n","            #Call function to create REAL data vector\n","            real_data = Variable(images_to_vectors(real_inp))\n","            #REAL labels\n","            real_labels = Variable(labels)\n","            #Call function to create FAKE labels\n","            fake_lbls = fake_labels(N)\n","            #Call function to create FAKE data vector\n","            fake_data = generator(create_noise(N), fake_lbls).detach()    #The detach() method constructs a new view on a tensor which is declared not to need gradients\n","\n","            # Train Discriminator\n","            disc_loss, d_pred_real, d_pred_fake = train_discriminator(real_data, real_labels, fake_data, fake_lbls, dis_opt, N)\n","\n","            #Forward a random vector through the Generator to obtain the synthetized output\n","            fake_data = generator(create_noise(N),fake_lbls)\n","\n","            # Train Generator\n","            gen_loss = train_generator(fake_data, gen_opt, N)\n","\n","\n","            # Print losses for each epoch\n","            if (batch_idx) % 100 == 0:\n","                print(f'Epoch {epoch}: Batch {batch_idx} Discrim loss {disc_loss}, Generator loss {gen_loss}')\n","                gen_losses.append(gen_loss)\n","                dis_losses.append(disc_loss)\n","                losses = {'gen_losses':gen_losses, 'dis_losses':dis_losses}\n","                label_to_display = create_label_num(num_test_samples)\n","                test_images = vectors_to_images(generator(test_noise,label_to_display))\n","                plot_gen_img(test_images)\n","\n","    # Print Graphic of gen and discr losses   \n","    plt.figure(figsize=(10, 8))\n","    plt.xlabel('Epoch')\n","    plt.ylabel('MSE')\n","    plt.plot(gen_losses, label='GEN')\n","    plt.plot(dis_losses, label='DISC')\n","    plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nWMmf2Zns0Iz","colab_type":"text"},"source":["Train model"]},{"cell_type":"code","metadata":{"id":"kwwaRQAvs1cY","colab_type":"code","outputId":"4318622f-bd14-497a-a7b7-3f2ae1a0e207","executionInfo":{"status":"ok","timestamp":1575366067550,"user_tz":-60,"elapsed":2832333,"user":{"displayName":"Marti Grau Gasulla","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB9fMvTXDuVkvtOgF8K--sg9b9UhdIvFz2A6q2UvbQ=s64","userId":"03128845478504801773"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1U-fwSRDacFmMNeSTxBcjnVkFTDvHfwmj"}},"source":["train_net(train_loader, gen_optimizer, dis_optimizer, hparams['num_epochs'])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"SBAIj4jkmttH","colab_type":"text"},"source":["In this section we will test the generator printing all the numbers"]},{"cell_type":"code","metadata":{"id":"wUnqssg9m0Wh","colab_type":"code","colab":{}},"source":["noise_vector = Variable(torch.randn(100, 100))\n","labels = Variable(torch.LongTensor([i for _ in range(10) for i in range(10)]))\n","num_images = vectors_to_images(generator(noise_vector, labels))\n","grid = make_grid(num_images, nrow=10, normalize=True).permute(1,2,0).numpy()\n","fig, ax = plt.subplots(figsize=(15,15))\n","ax.imshow(grid)\n","_ = plt.yticks([])\n","_ = plt.xticks(np.arange(15, 300, 30), ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], fontsize=20)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8eJ7YVy0k8cX","colab_type":"text"},"source":["In this section we will be able select the number and generate it: "]},{"cell_type":"code","metadata":{"id":"MMSWjfKwk46s","colab_type":"code","colab":{}},"source":["# Select number to generate:\n","NUM_TO_GENERATE = 3\n","random_noise = create_noise(1) # Noise vector to send it through the generator\n","\n","num_image = vectors_to_images(generator(random_noise,NUM_TO_GENERATE))\n","plot_gen_img(num_image)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e6Ymj83zwZYi","colab_type":"text"},"source":["-----------------------------------------------------------------------"]}]}