{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team06.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXEMd6fjMDxv",
        "colab_type": "text"
      },
      "source": [
        "#Exercise 1: Convolutional Autoencoder#\n",
        "\n",
        "Train a convolutional autoencoder on MNIST, study the influence of the bottleneck size and generate some images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI2YUDCIMl60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "torch.manual_seed(1)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(1)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UY29exSOCzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's define some hyper-parameters\n",
        "hparams = {\n",
        "    'batch_size':64,\n",
        "    'num_epochs':10,\n",
        "    'test_batch_size':64,\n",
        "    'hidden_size':128,\n",
        "    'learning_rate':1e-3,\n",
        "    'log_interval':100,\n",
        "}\n",
        "\n",
        "# we select to work on GPU if it is available in the machine, otherwise\n",
        "# will run on CPU\n",
        "hparams['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toHzJwqpOn4_",
        "colab_type": "text"
      },
      "source": [
        "**Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ-ESSIPOu6b",
        "colab_type": "code",
        "outputId": "d11b3496-b36f-4aba-f827-2d87a1e28c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "mnist_trainset = datasets.MNIST('data', train=True, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))                        \n",
        "                                ]))\n",
        "mnist_testset = datasets.MNIST('data', train=False, \n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.1307,), (0.3081,))\n",
        "                               ]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 5113853.74it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 129690.47it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2138910.14it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 47210.74it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ficutcOO9OD",
        "colab_type": "text"
      },
      "source": [
        "**Split data**:\n",
        "We split the data in 95% for training and 5% for validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVjEIXDAPKPG",
        "colab_type": "code",
        "outputId": "042ffac3-7a8b-4aa0-bcc2-ae90bed9c444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#we take the size of the trainset and after that we take 5% of dataset\n",
        "tvdataset_length = len(mnist_trainset)\n",
        "validationset_length = int(0.05*tvdataset_length)\n",
        "#we split the dataset\n",
        "[trainset,validationset]=torch.utils.data.random_split(mnist_trainset,[tvdataset_length-validationset_length,validationset_length])\n",
        "print('Validation dataset is :{}%'.format(100*len(validationset)/len(mnist_trainset)))\n",
        "print('Training dataset is :{}%'.format(100*len(trainset)/len(mnist_trainset)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation dataset is :5.0%\n",
            "Training dataset is :95.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCw_FrqyPbEf",
        "colab_type": "text"
      },
      "source": [
        "**Loader data**\n",
        "We load the dataset with batch size "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9SY3Wd2P2as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=hparams['batch_size'], \n",
        "    shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(\n",
        "    validationset,\n",
        "    batch_size=hparams['batch_size'], \n",
        "    shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "     mnist_testset,\n",
        "    batch_size=hparams['test_batch_size'], \n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujmQBiU-P_24",
        "colab_type": "text"
      },
      "source": [
        "## 2. Implement a convolutional autoencoder (with separate Encoder and Decoder modules). ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e1z86RQQLIP",
        "colab_type": "text"
      },
      "source": [
        "**Creation of the Class Autoencoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFrAUZ3I0rXu",
        "colab_type": "text"
      },
      "source": [
        "**Define of the Class encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy3qem8CxhF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,bottleneck):\n",
        "    super().__init__()\n",
        "    self.bottleneck = bottleneck\n",
        "    self.conv1 = nn.Sequential( \n",
        "              nn.Conv2d(1,32,5,padding=2),\n",
        "              nn.BatchNorm2d(32),\n",
        "              nn.MaxPool2d(2,2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.5))\n",
        "    self.conv2 = nn.Sequential(\n",
        "              nn.Conv2d(32,16,5,padding=2),\n",
        "              nn.BatchNorm2d(16),\n",
        "              nn.MaxPool2d(2,2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.5),\n",
        "              nn.Flatten())\n",
        "    self.fc = nn.Sequential(\n",
        "              nn.Linear(16*7*7,self.bottleneck),\n",
        "              nn.ReLU())\n",
        "  def forward(self,x):\n",
        "    x= self.conv1(x)\n",
        "    x= self.conv2(x)\n",
        "    x= self.fc(x)\n",
        "    return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKpWhH-p0y7X",
        "colab_type": "text"
      },
      "source": [
        "**Define of the class Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G003wB2C03Ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,bottleneck):\n",
        "    super().__init__()\n",
        "    self.bottleneck = bottleneck\n",
        "    self.conv1 = nn.Sequential( \n",
        "          nn.ConvTranspose2d(64,32,14,stride=2),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.5))\n",
        "    self.conv2 = nn.Sequential(\n",
        "          nn.ConvTranspose2d(32,1,2,stride=2),\n",
        "          nn.BatchNorm2d(1),\n",
        "          nn.Sigmoid())\n",
        "    self.fc = nn.Sequential(\n",
        "          nn.Linear(self.bottleneck,64),\n",
        "          nn.ReLU())\n",
        "  def forward(self,x):\n",
        "    x= self.fc(x)\n",
        "    x= self.conv1(x.view(x.shape[0], 64, 1,1))\n",
        "    x= self.conv2(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjXKNbo-2K6L",
        "colab_type": "text"
      },
      "source": [
        "**Define of the class Autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQlv3B8z2RsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,bottleneck):\n",
        "      super().__init__()\n",
        "      self.bottleneck = bottleneck\n",
        "      self.encoder = Encoder(self.bottleneck)\n",
        "      self.decoder = Decoder(self.bottleneck)\n",
        "    def forward(self,x):\n",
        "      x= self.encoder(x)\n",
        "      x= self.decoder(x)\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8EQA1d1QjR_",
        "colab_type": "text"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aeZYUpvYLr3",
        "colab_type": "text"
      },
      "source": [
        "Definition of the function *train epoch*. It train the weights of the model. It computes the loss of the train and it performs the backpropagation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwXY1cVk_Df5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(train_loader,model,optimizer,criterion,hparams):\n",
        "  model.train()\n",
        "  avg_loss_train = None\n",
        "  avg_weight = 0.1\n",
        "  for data in train_loader:\n",
        "          optimizer.zero_grad()\n",
        "          img, _ = data\n",
        "          img = img.cuda()\n",
        "          output = model(img)\n",
        "          loss = criterion(output,img)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if avg_loss_train:\n",
        "            avg_loss_train = avg_weight * loss.item() + (1 - avg_weight) * avg_loss_train\n",
        "          else:\n",
        "            avg_loss_train = loss.item() \n",
        "  return avg_loss_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6UAzZfgczS7",
        "colab_type": "text"
      },
      "source": [
        "It is a generic fonction to evaluate the model it return the loss average and the MSE. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kH7nzyIIcnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_epoch(set_loader,model,hparams):\n",
        "  model.eval()\n",
        "  avg_loss_validation =0\n",
        "  MSE = 0\n",
        "  with torch.no_grad():\n",
        "    for data in set_loader:\n",
        "      img,_ = data\n",
        "      img = img.cuda()\n",
        "      output = model(img)\n",
        "      val_loss = criterion(output,img)\n",
        "      MSE += criterion_MSE(output,img)\n",
        "      avg_loss_validation+= val_loss\n",
        "  avg_loss_validation /= len(set_loader)\n",
        "  MSE /= len(set_loader) \n",
        "  return avg_loss_validation,MSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTxKC70ndCj7",
        "colab_type": "text"
      },
      "source": [
        "###Train of the model and evalutation of it with different bottleneck###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFBr5C6VhhKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class my_dictionary(dict): \n",
        "  \n",
        "    # __init__ function \n",
        "    def __init__(self): \n",
        "        self = dict() \n",
        "          \n",
        "    # Function to add key:value \n",
        "    def add(self, key, value): \n",
        "        self[key] = value "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hLCJnupgoCz",
        "colab_type": "code",
        "outputId": "febc76c7-57bb-4782-dead-2fb3a3017dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "validation_bottleneck_MSE= my_dictionary()\n",
        "test_bottleneck_MSE = my_dictionary()\n",
        "validation_loss_bottleneck = my_dictionary()\n",
        "train_loss_bottleneck = my_dictionary()\n",
        "for bottleneck in range(1,20,4):\n",
        "  model = Autoencoder(bottleneck).cuda()\n",
        "  model.to(hparams['device'])\n",
        "  list_MSE_validation = []\n",
        "  train_loss = []\n",
        "  validation_loss = []\n",
        "  criterion_MSE = nn.MSELoss()\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer =  optim.Adam(model.parameters(), lr=hparams['learning_rate'])\n",
        "  print('Bottleneck :{}'.format(bottleneck))\n",
        "  \n",
        "  for epoch in range(hparams['num_epochs']):\n",
        "    loss_train = train_epoch(train_loader,model,optimizer,criterion,hparams)\n",
        "    val_loss,MSE_validation = test_epoch(validation_loader,model,hparams)\n",
        "    train_loss.append(loss_train)\n",
        "    validation_loss.append(val_loss)\n",
        "    list_MSE_validation.append(MSE_validation)\n",
        "    print('Train epoch [{}/{}], loss:{:.4f}, validation loss = {:.4f}, MSE:{:.2f}'.format(epoch+1, hparams['num_epochs'], loss_train,val_loss,MSE_validation))\n",
        "  _,test_MSE = test_epoch(test_loader,model,hparams)\n",
        "  validation_loss_bottleneck.add(bottleneck,train_loss)\n",
        "  validation_loss_bottleneck.add(bottleneck,validation_loss)\n",
        "  validation_bottleneck_MSE.add(bottleneck,list_MSE_validation[-1].item())   \n",
        "  test_bottleneck_MSE.add(bottleneck,test_MSE.item())\n",
        "  print(validation_bottleneck_MSE)\n",
        "  print(test_bottleneck_MSE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bottleneck :1\n",
            "Train epoch [1/10], loss:-0.4187, validation loss = -0.4333, MSE:0.83\n",
            "Train epoch [2/10], loss:-0.8741, validation loss = -0.9078, MSE:0.76\n",
            "Train epoch [3/10], loss:-1.3087, validation loss = -1.3379, MSE:0.74\n",
            "Train epoch [4/10], loss:-1.7178, validation loss = -1.7619, MSE:0.73\n",
            "Train epoch [5/10], loss:-2.1517, validation loss = -2.1811, MSE:0.73\n",
            "Train epoch [6/10], loss:-2.5726, validation loss = -2.5791, MSE:0.73\n",
            "Train epoch [7/10], loss:-3.0274, validation loss = -2.9649, MSE:0.72\n",
            "Train epoch [8/10], loss:-3.4456, validation loss = -3.4110, MSE:0.72\n",
            "Train epoch [9/10], loss:-3.9397, validation loss = -3.8314, MSE:0.72\n",
            "Train epoch [10/10], loss:-4.3060, validation loss = -4.2625, MSE:0.72\n",
            "{1: 0.7189732789993286}\n",
            "{1: 0.7251156568527222}\n",
            "Bottleneck :5\n",
            "Train epoch [1/10], loss:-0.7030, validation loss = -0.7056, MSE:0.74\n",
            "Train epoch [2/10], loss:-1.3586, validation loss = -1.3689, MSE:0.64\n",
            "Train epoch [3/10], loss:-1.9172, validation loss = -1.9093, MSE:0.61\n",
            "Train epoch [4/10], loss:-2.4865, validation loss = -2.4776, MSE:0.60\n",
            "Train epoch [5/10], loss:-3.0504, validation loss = -2.9592, MSE:0.59\n",
            "Train epoch [6/10], loss:-3.5842, validation loss = -3.5249, MSE:0.59\n",
            "Train epoch [7/10], loss:-4.1179, validation loss = -4.0814, MSE:0.59\n",
            "Train epoch [8/10], loss:-4.6662, validation loss = -4.6464, MSE:0.59\n",
            "Train epoch [9/10], loss:-5.1787, validation loss = -5.2219, MSE:0.58\n",
            "Train epoch [10/10], loss:-5.7056, validation loss = -5.7202, MSE:0.58\n",
            "{1: 0.7189732789993286, 5: 0.5834451913833618}\n",
            "{1: 0.7251156568527222, 5: 0.5929722785949707}\n",
            "Bottleneck :9\n",
            "Train epoch [1/10], loss:-0.7835, validation loss = -0.7915, MSE:0.72\n",
            "Train epoch [2/10], loss:-1.4352, validation loss = -1.4335, MSE:0.63\n",
            "Train epoch [3/10], loss:-1.9928, validation loss = -1.9964, MSE:0.60\n",
            "Train epoch [4/10], loss:-2.5649, validation loss = -2.5276, MSE:0.58\n",
            "Train epoch [5/10], loss:-3.1205, validation loss = -3.1079, MSE:0.58\n",
            "Train epoch [6/10], loss:-3.7235, validation loss = -3.6009, MSE:0.58\n",
            "Train epoch [7/10], loss:-4.2548, validation loss = -4.1986, MSE:0.57\n",
            "Train epoch [8/10], loss:-4.7711, validation loss = -4.7676, MSE:0.57\n",
            "Train epoch [9/10], loss:-5.3178, validation loss = -5.4050, MSE:0.57\n",
            "Train epoch [10/10], loss:-5.8898, validation loss = -5.9493, MSE:0.57\n",
            "{1: 0.7189732789993286, 5: 0.5834451913833618, 9: 0.5710442066192627}\n",
            "{1: 0.7251156568527222, 5: 0.5929722785949707, 9: 0.5798278450965881}\n",
            "Bottleneck :13\n",
            "Train epoch [1/10], loss:-0.8590, validation loss = -0.8489, MSE:0.70\n",
            "Train epoch [2/10], loss:-1.5145, validation loss = -1.4935, MSE:0.60\n",
            "Train epoch [3/10], loss:-2.1172, validation loss = -2.0926, MSE:0.57\n",
            "Train epoch [4/10], loss:-2.7291, validation loss = -2.6843, MSE:0.55\n",
            "Train epoch [5/10], loss:-3.3022, validation loss = -3.2831, MSE:0.55\n",
            "Train epoch [6/10], loss:-3.9186, validation loss = -3.7910, MSE:0.55\n",
            "Train epoch [7/10], loss:-4.4752, validation loss = -4.4888, MSE:0.54\n",
            "Train epoch [8/10], loss:-5.0424, validation loss = -5.0281, MSE:0.54\n",
            "Train epoch [9/10], loss:-5.6785, validation loss = -5.6586, MSE:0.54\n",
            "Train epoch [10/10], loss:-6.1756, validation loss = -6.3122, MSE:0.54\n",
            "{1: 0.7189732789993286, 5: 0.5834451913833618, 9: 0.5710442066192627, 13: 0.5405207276344299}\n",
            "{1: 0.7251156568527222, 5: 0.5929722785949707, 9: 0.5798278450965881, 13: 0.5489012598991394}\n",
            "Bottleneck :17\n",
            "Train epoch [1/10], loss:-0.8357, validation loss = -0.8666, MSE:0.70\n",
            "Train epoch [2/10], loss:-1.5083, validation loss = -1.5447, MSE:0.60\n",
            "Train epoch [3/10], loss:-2.1544, validation loss = -2.1759, MSE:0.56\n",
            "Train epoch [4/10], loss:-2.7672, validation loss = -2.7393, MSE:0.55\n",
            "Train epoch [5/10], loss:-3.3511, validation loss = -3.2924, MSE:0.54\n",
            "Train epoch [6/10], loss:-3.9661, validation loss = -3.9098, MSE:0.54\n",
            "Train epoch [7/10], loss:-4.6088, validation loss = -4.4900, MSE:0.53\n",
            "Train epoch [8/10], loss:-5.1967, validation loss = -5.1421, MSE:0.53\n",
            "Train epoch [9/10], loss:-5.7794, validation loss = -5.8206, MSE:0.53\n",
            "Train epoch [10/10], loss:-6.3562, validation loss = -6.5583, MSE:0.53\n",
            "{1: 0.7189732789993286, 5: 0.5834451913833618, 9: 0.5710442066192627, 13: 0.5405207276344299, 17: 0.5293729305267334}\n",
            "{1: 0.7251156568527222, 5: 0.5929722785949707, 9: 0.5798278450965881, 13: 0.5489012598991394, 17: 0.5369264483451843}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9U4c-MGWtg",
        "colab_type": "text"
      },
      "source": [
        "Plot the Loss and the MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XfpNMJr7Wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "negpfwPv6J7U",
        "colab_type": "code",
        "outputId": "fe689ef7-b19e-4616-d808-2beb3ad7726e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "bottleneck = 15\n",
        "model = Autoencoder(bottleneck).cuda()\n",
        "model.to(hparams['device'])\n",
        "list_MSE_validation = []\n",
        "list_MSE_test = []\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "list_test_loss = []\n",
        "criterion_MSE = nn.MSELoss()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer =  optim.Adam(model.parameters(), lr=hparams['learning_rate'])\n",
        "for epoch in range(hparams['num_epochs']):\n",
        "  loss_train = train_epoch(train_loader,model,optimizer,criterion,hparams)\n",
        "  val_loss,MSE_validation = test_epoch(validation_loader,model,hparams)\n",
        "  test_loss,MSE_test = test_epoch(test_loader,model,hparams)\n",
        "  train_loss.append(loss_train)\n",
        "  validation_loss.append(val_loss)\n",
        "  list_test_loss.append(test_loss)\n",
        "  list_MSE_validation.append(MSE_validation)\n",
        "  list_MSE_test.append(MSE_test)\n",
        "  print('Train epoch [{}/{}], loss:{:.4f}, validation loss = {:.4f}, MSE:{:.2f}'\n",
        "  .format(epoch+1, hparams['num_epochs'], loss_train,val_loss,MSE_validation))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch [1/10], loss:-0.8541, validation loss = -0.8561, MSE:0.70\n",
            "Train epoch [2/10], loss:-1.5248, validation loss = -1.5130, MSE:0.60\n",
            "Train epoch [3/10], loss:-2.1280, validation loss = -2.1432, MSE:0.56\n",
            "Train epoch [4/10], loss:-2.7421, validation loss = -2.7241, MSE:0.55\n",
            "Train epoch [5/10], loss:-3.3477, validation loss = -3.3362, MSE:0.54\n",
            "Train epoch [6/10], loss:-3.9677, validation loss = -3.8805, MSE:0.54\n",
            "Train epoch [7/10], loss:-4.5866, validation loss = -4.5201, MSE:0.54\n",
            "Train epoch [8/10], loss:-5.1686, validation loss = -5.0974, MSE:0.54\n",
            "Train epoch [9/10], loss:-5.7250, validation loss = -5.7878, MSE:0.53\n",
            "Train epoch [10/10], loss:-6.3062, validation loss = -6.3988, MSE:0.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z2eM85OkyRz",
        "colab_type": "code",
        "outputId": "83a94699-6607-47c9-8335-61c8f5675eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('BCEloss')\n",
        "plt.plot(train_loss,'r', label='train loss' )\n",
        "plt.plot(validation_loss,'b',label='validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd6932c5588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAHgCAYAAAACM9GVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW95HDZbou3P",
        "colab_type": "text"
      },
      "source": [
        "##Compute of the MSE##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0eJOldzpFx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXDCWQFSqV1-",
        "colab_type": "text"
      },
      "source": [
        "Display of 5 random images and the ouput of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaiwCPcbqsPl",
        "colab_type": "code",
        "outputId": "98c2e00f-01fc-49b3-8cdd-e28b0e88c2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#take 5 random images\n",
        "random_set_loader = torch.utils.data.DataLoader(\n",
        "     mnist_testset,\n",
        "    batch_size=5, \n",
        "    shuffle=True)\n",
        "dataiter = iter(random_set_loader)\n",
        "images,_ =dataiter.next()\n",
        "images = images.cuda()\n",
        "output = model(images)\n",
        "images = images.cpu().detach().numpy()\n",
        "output = output.cpu().detach().numpy()\n",
        "fig, axes = plt.subplots(nrows=2,ncols=5,sharex=True,sharey=True,figsize=(25,4\n",
        "))  \n",
        "for images, row in zip([images, output],axes):\n",
        "  for img,ax in zip(images,row):\n",
        "    ax.imshow(np.squeeze(img), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABPcAAADrCAYAAAAFQXMxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQE7Z3AMAAACAnLK5BwAAAAA59f8AoOpr79/qkLAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1800x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7srcwHlp_MNl",
        "colab_type": "text"
      },
      "source": [
        "**Generate 5 new images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsUkKTwPBBwk",
        "colab_type": "code",
        "outputId": "e932035b-2014-445e-b407-e6ead30738c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#for i in range(5):\n",
        "nb_images = 5\n",
        "rand_features = torch.randn(nb_images, bottleneck).to(hparams['device']) \n",
        "output = model.decoder(rand_features)\n",
        "#Visualisation\n",
        "output = output.cpu().detach().numpy()\n",
        "images_width = 28\n",
        "fig, axes = plt.subplots(nrows=1,ncols=5,sharex=True,sharey=True,figsize=(25,4))\n",
        "decoded_images = output[:nb_images]  \n",
        "for ax, img in zip(axes, decoded_images):\n",
        "    ax.imshow(np.squeeze(img), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAADrCAYAAAASRrTRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1800x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swhbaAJcdVh2",
        "colab_type": "text"
      },
      "source": [
        "#Exercice 2#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ImVXmujF46",
        "colab_type": "text"
      },
      "source": [
        "We take a subset of 100 images and their associates label from the MNIST training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thhTDz6pjFG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_images_subnet = 100\n",
        "[trainset,_]=torch.utils.data.random_split(mnist_trainset,[nb_images_subnet,tvdataset_length-nb_images_subnet])\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=hparams['batch_size'], \n",
        "    shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khqkApdIfVqv",
        "colab_type": "text"
      },
      "source": [
        "We first take the layers of the encoder part of the  model autoencoder. We take the one with a bottleneck of length 15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2vkIG0PdYJ_",
        "colab_type": "code",
        "outputId": "1a6ec10f-b701-42a8-8fd2-9e380b399059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "encoder_pretrain = model.encoder \n",
        "encoder_pretrain.eval()\n",
        "encoder_pretrain.to(hparams['device'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): ReLU()\n",
              "    (4): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): ReLU()\n",
              "    (4): Dropout(p=0.5, inplace=False)\n",
              "    (5): Flatten()\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=15, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzxwhWz3li9x",
        "colab_type": "text"
      },
      "source": [
        "We create the classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myOiDVjwmvtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bottleneck = 15\n",
        "class Classification(nn.Module):\n",
        "  def __init__(self,endoder):\n",
        "    super().__init__()\n",
        "    self.layers = endoder\n",
        "    #fully connected layers\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(bottleneck,10),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.layers(x)\n",
        "    x= self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuogcDR2oMIU",
        "colab_type": "text"
      },
      "source": [
        "Training with the previous weights. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhFbZABsoslF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "89044dcb-b809-4b79-b445-11019c6df7a7"
      },
      "source": [
        "model_classifier = Classification(encoder_pretrain)\n",
        "for layer in list(model_classifier.layers):\n",
        "  for param in layer.parameters():\n",
        "    param.require_grad = False    #Freeze layers of the encoder"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6b96fd7099c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_pretrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m    \u001b[0;31m#Freeze layers of the encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Classification' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbQVpxWy_yeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_predictions(predicted_batch, label_batch):\n",
        "  pred = predicted_batch.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "  acum = pred.eq(label_batch.view_as(pred)).sum().item()\n",
        "  return acum\n",
        "\n",
        "def train_epoch(train_loader, network, optimizer, criterion, hparams):\n",
        "  # Activate the train=True flag inside the model\n",
        "  network.train()\n",
        "  device = hparams['device']\n",
        "  avg_loss = None\n",
        "  avg_weight = 0.1\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model_classifier(data)\n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      if avg_loss:\n",
        "        avg_loss = avg_weight * loss.item() + (1 - avg_weight) * avg_loss\n",
        "      else:\n",
        "        avg_loss = loss.item()\n",
        "      optimizer.step()\n",
        "      if batch_idx % hparams['log_interval'] == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "              100. * batch_idx / len(train_loader), loss.item()))\n",
        "  return avg_loss\n",
        "def test_epoch(test_loader, network, hparams):\n",
        "    network.eval()\n",
        "    device = hparams['device']\n",
        "    test_loss = 0\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model_classifier(data)\n",
        "            test_loss += criterion(output, target, reduction='sum').item() # sum up batch loss\n",
        "            # compute number of correct predictions in the batch\n",
        "            acc += correct_predictions(output, target)\n",
        "    # Average acc across all correct predictions batches now\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = 100. * acc / len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, acc, len(test_loader.dataset), test_acc,\n",
        "        ))\n",
        "    return test_loss, test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL5CyLd1Ir7I",
        "colab_type": "code",
        "outputId": "f5bc44da-871d-4e1c-90c3-3a214f4de1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tr_losses = []\n",
        "te_losses = []\n",
        "te_accs = []\n",
        "model_classifier.to(hparams['device'])\n",
        "optimizer = optim.RMSprop(model_classifier.parameters(), lr=hparams['learning_rate'])\n",
        "criterion = F.nll_loss\n",
        "\n",
        "for epoch in range(1, hparams['num_epochs'] + 50):\n",
        "  tr_losses.append(train_epoch(train_loader, model_classifier, optimizer, criterion, hparams))\n",
        "  te_loss, te_acc = test_epoch(test_loader, model_classifier, hparams)\n",
        "  te_losses.append(te_loss)\n",
        "  te_accs.append(te_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/100 (0%)]\tLoss: -0.082447\n",
            "\n",
            "Test set: Average loss: -0.1364, Accuracy: 1406/10000 (14%)\n",
            "\n",
            "Train Epoch: 2 [0/100 (0%)]\tLoss: -0.162588\n",
            "\n",
            "Test set: Average loss: -0.2054, Accuracy: 2643/10000 (26%)\n",
            "\n",
            "Train Epoch: 3 [0/100 (0%)]\tLoss: -0.305485\n",
            "\n",
            "Test set: Average loss: -0.2655, Accuracy: 3141/10000 (31%)\n",
            "\n",
            "Train Epoch: 4 [0/100 (0%)]\tLoss: -0.318949\n",
            "\n",
            "Test set: Average loss: -0.3018, Accuracy: 3385/10000 (34%)\n",
            "\n",
            "Train Epoch: 5 [0/100 (0%)]\tLoss: -0.443720\n",
            "\n",
            "Test set: Average loss: -0.3218, Accuracy: 3614/10000 (36%)\n",
            "\n",
            "Train Epoch: 6 [0/100 (0%)]\tLoss: -0.442210\n",
            "\n",
            "Test set: Average loss: -0.3453, Accuracy: 3846/10000 (38%)\n",
            "\n",
            "Train Epoch: 7 [0/100 (0%)]\tLoss: -0.528384\n",
            "\n",
            "Test set: Average loss: -0.3606, Accuracy: 3935/10000 (39%)\n",
            "\n",
            "Train Epoch: 8 [0/100 (0%)]\tLoss: -0.520575\n",
            "\n",
            "Test set: Average loss: -0.3625, Accuracy: 3909/10000 (39%)\n",
            "\n",
            "Train Epoch: 9 [0/100 (0%)]\tLoss: -0.528279\n",
            "\n",
            "Test set: Average loss: -0.3745, Accuracy: 4065/10000 (41%)\n",
            "\n",
            "Train Epoch: 10 [0/100 (0%)]\tLoss: -0.536959\n",
            "\n",
            "Test set: Average loss: -0.3797, Accuracy: 4114/10000 (41%)\n",
            "\n",
            "Train Epoch: 11 [0/100 (0%)]\tLoss: -0.562102\n",
            "\n",
            "Test set: Average loss: -0.3896, Accuracy: 4192/10000 (42%)\n",
            "\n",
            "Train Epoch: 12 [0/100 (0%)]\tLoss: -0.517508\n",
            "\n",
            "Test set: Average loss: -0.3969, Accuracy: 4237/10000 (42%)\n",
            "\n",
            "Train Epoch: 13 [0/100 (0%)]\tLoss: -0.605890\n",
            "\n",
            "Test set: Average loss: -0.4028, Accuracy: 4259/10000 (43%)\n",
            "\n",
            "Train Epoch: 14 [0/100 (0%)]\tLoss: -0.548234\n",
            "\n",
            "Test set: Average loss: -0.4199, Accuracy: 4481/10000 (45%)\n",
            "\n",
            "Train Epoch: 15 [0/100 (0%)]\tLoss: -0.508988\n",
            "\n",
            "Test set: Average loss: -0.4342, Accuracy: 4658/10000 (47%)\n",
            "\n",
            "Train Epoch: 16 [0/100 (0%)]\tLoss: -0.645837\n",
            "\n",
            "Test set: Average loss: -0.4386, Accuracy: 4688/10000 (47%)\n",
            "\n",
            "Train Epoch: 17 [0/100 (0%)]\tLoss: -0.564661\n",
            "\n",
            "Test set: Average loss: -0.4438, Accuracy: 4720/10000 (47%)\n",
            "\n",
            "Train Epoch: 18 [0/100 (0%)]\tLoss: -0.581459\n",
            "\n",
            "Test set: Average loss: -0.4533, Accuracy: 4808/10000 (48%)\n",
            "\n",
            "Train Epoch: 19 [0/100 (0%)]\tLoss: -0.636578\n",
            "\n",
            "Test set: Average loss: -0.4623, Accuracy: 4899/10000 (49%)\n",
            "\n",
            "Train Epoch: 20 [0/100 (0%)]\tLoss: -0.622497\n",
            "\n",
            "Test set: Average loss: -0.4565, Accuracy: 4807/10000 (48%)\n",
            "\n",
            "Train Epoch: 21 [0/100 (0%)]\tLoss: -0.651623\n",
            "\n",
            "Test set: Average loss: -0.4669, Accuracy: 4918/10000 (49%)\n",
            "\n",
            "Train Epoch: 22 [0/100 (0%)]\tLoss: -0.601826\n",
            "\n",
            "Test set: Average loss: -0.4749, Accuracy: 5012/10000 (50%)\n",
            "\n",
            "Train Epoch: 23 [0/100 (0%)]\tLoss: -0.657083\n",
            "\n",
            "Test set: Average loss: -0.4775, Accuracy: 5039/10000 (50%)\n",
            "\n",
            "Train Epoch: 24 [0/100 (0%)]\tLoss: -0.664874\n",
            "\n",
            "Test set: Average loss: -0.4758, Accuracy: 5000/10000 (50%)\n",
            "\n",
            "Train Epoch: 25 [0/100 (0%)]\tLoss: -0.644414\n",
            "\n",
            "Test set: Average loss: -0.4714, Accuracy: 4928/10000 (49%)\n",
            "\n",
            "Train Epoch: 26 [0/100 (0%)]\tLoss: -0.642190\n",
            "\n",
            "Test set: Average loss: -0.4879, Accuracy: 5118/10000 (51%)\n",
            "\n",
            "Train Epoch: 27 [0/100 (0%)]\tLoss: -0.632886\n",
            "\n",
            "Test set: Average loss: -0.4854, Accuracy: 5082/10000 (51%)\n",
            "\n",
            "Train Epoch: 28 [0/100 (0%)]\tLoss: -0.657409\n",
            "\n",
            "Test set: Average loss: -0.4883, Accuracy: 5112/10000 (51%)\n",
            "\n",
            "Train Epoch: 29 [0/100 (0%)]\tLoss: -0.670332\n",
            "\n",
            "Test set: Average loss: -0.4915, Accuracy: 5137/10000 (51%)\n",
            "\n",
            "Train Epoch: 30 [0/100 (0%)]\tLoss: -0.665263\n",
            "\n",
            "Test set: Average loss: -0.4897, Accuracy: 5116/10000 (51%)\n",
            "\n",
            "Train Epoch: 31 [0/100 (0%)]\tLoss: -0.615061\n",
            "\n",
            "Test set: Average loss: -0.4884, Accuracy: 5088/10000 (51%)\n",
            "\n",
            "Train Epoch: 32 [0/100 (0%)]\tLoss: -0.631752\n",
            "\n",
            "Test set: Average loss: -0.4937, Accuracy: 5143/10000 (51%)\n",
            "\n",
            "Train Epoch: 33 [0/100 (0%)]\tLoss: -0.603906\n",
            "\n",
            "Test set: Average loss: -0.4945, Accuracy: 5155/10000 (52%)\n",
            "\n",
            "Train Epoch: 34 [0/100 (0%)]\tLoss: -0.708917\n",
            "\n",
            "Test set: Average loss: -0.4891, Accuracy: 5084/10000 (51%)\n",
            "\n",
            "Train Epoch: 35 [0/100 (0%)]\tLoss: -0.682772\n",
            "\n",
            "Test set: Average loss: -0.4934, Accuracy: 5144/10000 (51%)\n",
            "\n",
            "Train Epoch: 36 [0/100 (0%)]\tLoss: -0.708167\n",
            "\n",
            "Test set: Average loss: -0.5001, Accuracy: 5215/10000 (52%)\n",
            "\n",
            "Train Epoch: 37 [0/100 (0%)]\tLoss: -0.667293\n",
            "\n",
            "Test set: Average loss: -0.5008, Accuracy: 5213/10000 (52%)\n",
            "\n",
            "Train Epoch: 38 [0/100 (0%)]\tLoss: -0.612671\n",
            "\n",
            "Test set: Average loss: -0.5000, Accuracy: 5205/10000 (52%)\n",
            "\n",
            "Train Epoch: 39 [0/100 (0%)]\tLoss: -0.658545\n",
            "\n",
            "Test set: Average loss: -0.5015, Accuracy: 5222/10000 (52%)\n",
            "\n",
            "Train Epoch: 40 [0/100 (0%)]\tLoss: -0.662849\n",
            "\n",
            "Test set: Average loss: -0.5042, Accuracy: 5246/10000 (52%)\n",
            "\n",
            "Train Epoch: 41 [0/100 (0%)]\tLoss: -0.579009\n",
            "\n",
            "Test set: Average loss: -0.5033, Accuracy: 5228/10000 (52%)\n",
            "\n",
            "Train Epoch: 42 [0/100 (0%)]\tLoss: -0.677219\n",
            "\n",
            "Test set: Average loss: -0.5013, Accuracy: 5213/10000 (52%)\n",
            "\n",
            "Train Epoch: 43 [0/100 (0%)]\tLoss: -0.701321\n",
            "\n",
            "Test set: Average loss: -0.4991, Accuracy: 5177/10000 (52%)\n",
            "\n",
            "Train Epoch: 44 [0/100 (0%)]\tLoss: -0.670693\n",
            "\n",
            "Test set: Average loss: -0.4961, Accuracy: 5135/10000 (51%)\n",
            "\n",
            "Train Epoch: 45 [0/100 (0%)]\tLoss: -0.624329\n",
            "\n",
            "Test set: Average loss: -0.5059, Accuracy: 5237/10000 (52%)\n",
            "\n",
            "Train Epoch: 46 [0/100 (0%)]\tLoss: -0.669328\n",
            "\n",
            "Test set: Average loss: -0.5098, Accuracy: 5277/10000 (53%)\n",
            "\n",
            "Train Epoch: 47 [0/100 (0%)]\tLoss: -0.664250\n",
            "\n",
            "Test set: Average loss: -0.5117, Accuracy: 5302/10000 (53%)\n",
            "\n",
            "Train Epoch: 48 [0/100 (0%)]\tLoss: -0.692448\n",
            "\n",
            "Test set: Average loss: -0.5128, Accuracy: 5308/10000 (53%)\n",
            "\n",
            "Train Epoch: 49 [0/100 (0%)]\tLoss: -0.642353\n",
            "\n",
            "Test set: Average loss: -0.5136, Accuracy: 5307/10000 (53%)\n",
            "\n",
            "Train Epoch: 50 [0/100 (0%)]\tLoss: -0.667047\n",
            "\n",
            "Test set: Average loss: -0.5119, Accuracy: 5292/10000 (53%)\n",
            "\n",
            "Train Epoch: 51 [0/100 (0%)]\tLoss: -0.624809\n",
            "\n",
            "Test set: Average loss: -0.5119, Accuracy: 5282/10000 (53%)\n",
            "\n",
            "Train Epoch: 52 [0/100 (0%)]\tLoss: -0.708641\n",
            "\n",
            "Test set: Average loss: -0.5130, Accuracy: 5292/10000 (53%)\n",
            "\n",
            "Train Epoch: 53 [0/100 (0%)]\tLoss: -0.668702\n",
            "\n",
            "Test set: Average loss: -0.5159, Accuracy: 5325/10000 (53%)\n",
            "\n",
            "Train Epoch: 54 [0/100 (0%)]\tLoss: -0.665226\n",
            "\n",
            "Test set: Average loss: -0.5168, Accuracy: 5338/10000 (53%)\n",
            "\n",
            "Train Epoch: 55 [0/100 (0%)]\tLoss: -0.677333\n",
            "\n",
            "Test set: Average loss: -0.5176, Accuracy: 5342/10000 (53%)\n",
            "\n",
            "Train Epoch: 56 [0/100 (0%)]\tLoss: -0.604377\n",
            "\n",
            "Test set: Average loss: -0.5155, Accuracy: 5318/10000 (53%)\n",
            "\n",
            "Train Epoch: 57 [0/100 (0%)]\tLoss: -0.693760\n",
            "\n",
            "Test set: Average loss: -0.5158, Accuracy: 5314/10000 (53%)\n",
            "\n",
            "Train Epoch: 58 [0/100 (0%)]\tLoss: -0.647305\n",
            "\n",
            "Test set: Average loss: -0.5152, Accuracy: 5303/10000 (53%)\n",
            "\n",
            "Train Epoch: 59 [0/100 (0%)]\tLoss: -0.661839\n",
            "\n",
            "Test set: Average loss: -0.5157, Accuracy: 5304/10000 (53%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}