{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team06.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXEMd6fjMDxv",
        "colab_type": "text"
      },
      "source": [
        "#Exercise 1: Convolutional Autoencoder#\n",
        "\n",
        "Train a convolutional autoencoder on MNIST, study the influence of the bottleneck size and generate some images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI2YUDCIMl60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "torch.manual_seed(1)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(1)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UY29exSOCzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's define some hyper-parameters\n",
        "hparams = {\n",
        "    'batch_size':64,\n",
        "    'num_epochs':1,\n",
        "    'test_batch_size':64,\n",
        "    'hidden_size':128,\n",
        "    'learning_rate':1e-3,\n",
        "    'log_interval':100,\n",
        "}\n",
        "\n",
        "# we select to work on GPU if it is available in the machine, otherwise\n",
        "# will run on CPU\n",
        "hparams['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toHzJwqpOn4_",
        "colab_type": "text"
      },
      "source": [
        "**Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ-ESSIPOu6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_trainset = datasets.MNIST('data', train=True, download=True,\n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.1307,), (0.3081,))                        \n",
        "                                ]))\n",
        "mnist_testset = datasets.MNIST('data', train=False, \n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.1307,), (0.3081,))\n",
        "                               ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ficutcOO9OD",
        "colab_type": "text"
      },
      "source": [
        "**Split data**:\n",
        "We split the data in 95% for training and 5% for validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVjEIXDAPKPG",
        "colab_type": "code",
        "outputId": "5bf6add0-c00c-4eaf-a47a-808148c32df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#we take the size of the trainset and after that we take 5% of dataset\n",
        "tvdataset_length = len(mnist_trainset)\n",
        "validationset_length = int(0.05*tvdataset_length)\n",
        "#we split the dataset\n",
        "[trainset,validationset]=torch.utils.data.random_split(mnist_trainset,[tvdataset_length-validationset_length,validationset_length])\n",
        "print('Validation dataset is :{}%'.format(100*len(validationset)/len(mnist_trainset)))\n",
        "print('Training dataset is :{}%'.format(100*len(trainset)/len(mnist_trainset)))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation dataset is :5.0%\n",
            "Training dataset is :95.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCw_FrqyPbEf",
        "colab_type": "text"
      },
      "source": [
        "**Loader data**\n",
        "We load the dataset with batch size "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9SY3Wd2P2as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=hparams['batch_size'], \n",
        "    shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(\n",
        "    validationset,\n",
        "    batch_size=hparams['batch_size'], \n",
        "    shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "     mnist_testset,\n",
        "    batch_size=hparams['test_batch_size'], \n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujmQBiU-P_24",
        "colab_type": "text"
      },
      "source": [
        "## 2. Implement a convolutional autoencoder (with separate Encoder and Decoder modules). ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e1z86RQQLIP",
        "colab_type": "text"
      },
      "source": [
        "**Creation of the Class Autoencoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFrAUZ3I0rXu",
        "colab_type": "text"
      },
      "source": [
        "**Define of the Class encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy3qem8CxhF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,bottleneck):\n",
        "    super().__init__()\n",
        "    self.bottleneck = bottleneck\n",
        "    self.conv1 = nn.Sequential( \n",
        "              nn.Conv2d(1,32,5,padding=2),\n",
        "              nn.BatchNorm2d(32),\n",
        "              nn.MaxPool2d(2,2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.5))\n",
        "    self.conv2 = nn.Sequential(\n",
        "              nn.Conv2d(32,16,5,padding=2),\n",
        "              nn.BatchNorm2d(16),\n",
        "              nn.MaxPool2d(2,2),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.5),\n",
        "              nn.Flatten())\n",
        "    self.fc = nn.Sequential(\n",
        "              nn.Linear(16*7*7,self.bottleneck),\n",
        "              nn.ReLU())\n",
        "  def forward(self,x):\n",
        "    x= self.conv1(x)\n",
        "    x= self.conv2(x)\n",
        "    x= self.fc(x)\n",
        "    return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKpWhH-p0y7X",
        "colab_type": "text"
      },
      "source": [
        "**Define of the class Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G003wB2C03Ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,bottleneck):\n",
        "    super().__init__()\n",
        "    self.bottleneck = bottleneck\n",
        "    self.conv1 = nn.Sequential( \n",
        "          nn.ConvTranspose2d(64,32,14,stride=2),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.5))\n",
        "    self.conv2 = nn.Sequential(\n",
        "          nn.ConvTranspose2d(32,1,2,stride=2),\n",
        "          nn.BatchNorm2d(1),\n",
        "          nn.Sigmoid())\n",
        "    self.fc = nn.Sequential(\n",
        "          nn.Linear(self.bottleneck,64),\n",
        "          nn.ReLU())\n",
        "  def forward(self,x):\n",
        "    x= self.fc(x)\n",
        "    x= self.conv1(x.view(x.shape[0], 64, 1,1))\n",
        "    x= self.conv2(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjXKNbo-2K6L",
        "colab_type": "text"
      },
      "source": [
        "**Define of the class Autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQlv3B8z2RsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,bottleneck):\n",
        "      super().__init__()\n",
        "      self.bottleneck = bottleneck\n",
        "      self.encoder = Encoder(self.bottleneck)\n",
        "      self.decoder = Decoder(self.bottleneck)\n",
        "    def forward(self,x):\n",
        "      x= self.encoder(x)\n",
        "      x= self.decoder(x)\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8EQA1d1QjR_",
        "colab_type": "text"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aeZYUpvYLr3",
        "colab_type": "text"
      },
      "source": [
        "Definition of the function *train epoch*. It train the weights of the model. It computes the loss of the train and it performs the backpropagation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwXY1cVk_Df5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(train_loader,model,optimizer,criterion,hparams):\n",
        "  model.train()\n",
        "  avg_loss_train = None\n",
        "  avg_weight = 0.1\n",
        "  for data in train_loader:\n",
        "          optimizer.zero_grad()\n",
        "          img, _ = data\n",
        "          img = img.cuda()\n",
        "          output = model(img)\n",
        "          loss = criterion(output,img)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if avg_loss_train:\n",
        "            avg_loss_train = avg_weight * loss.item() + (1 - avg_weight) * avg_loss_train\n",
        "          else:\n",
        "            avg_loss_train = loss.item() \n",
        "  return avg_loss_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6UAzZfgczS7",
        "colab_type": "text"
      },
      "source": [
        "It is a generic fonction to evaluate the model it return the loss average and the MSE. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kH7nzyIIcnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_epoch(set_loader,model,hparams):\n",
        "  model.eval()\n",
        "  avg_loss_validation =0\n",
        "  MSE = 0\n",
        "  with torch.no_grad():\n",
        "    for data in set_loader:\n",
        "      img,_ = data\n",
        "      img = img.cuda()\n",
        "      output = model(img)\n",
        "      val_loss = criterion(output,img)\n",
        "      MSE += criterion_MSE(output,img)\n",
        "      avg_loss_validation+= val_loss\n",
        "  avg_loss_validation /= len(set_loader)\n",
        "  MSE /= len(set_loader) \n",
        "  return avg_loss_validation,MSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTxKC70ndCj7",
        "colab_type": "text"
      },
      "source": [
        "###Train of the model and evalutation of it with different bottleneck###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFBr5C6VhhKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class my_dictionary(dict): \n",
        "  \n",
        "    # __init__ function \n",
        "    def __init__(self): \n",
        "        self = dict() \n",
        "          \n",
        "    # Function to add key:value \n",
        "    def add(self, key, value): \n",
        "        self[key] = value "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hLCJnupgoCz",
        "colab_type": "code",
        "outputId": "af619fa9-c6c7-421f-f200-63d382183904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "dic_MSE = dict()\n",
        "validation_loss_bottleneck = my_dictionary()\n",
        "train_loss_bottleneck = my_dictionary()\n",
        "for bottleneck in range(1,20,4):\n",
        "  model = Autoencoder(bottleneck).cuda()\n",
        "  model.to(hparams['device'])\n",
        "  list_MSE_validation = []\n",
        "  train_loss = []\n",
        "  validation_loss = []\n",
        "  criterion_MSE = nn.MSELoss()\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer =  optim.Adam(model.parameters(), lr=hparams['learning_rate'])\n",
        "  print('Bottleneck :{}'.format(bottleneck))\n",
        "  \n",
        "  for epoch in range(hparams['num_epochs']):\n",
        "    loss_train = train_epoch(train_loader,model,optimizer,criterion,hparams)\n",
        "    val_loss,MSE_validation = test_epoch(validation_loader,model,hparams)\n",
        "    train_loss.append(loss_train)\n",
        "    validation_loss.append(val_loss)\n",
        "    list_MSE_validation.append(MSE_validation)\n",
        "    print('Train epoch [{}/{}], loss:{:.4f}, validation loss = {:.4f}, MSE:{:.2f}'.format(epoch+1, hparams['num_epochs'], loss_train,val_loss,MSE_validation))\n",
        "  _,test_MSE = test_epoch(test_loader,model,hparams)\n",
        "  validation_loss_bottleneck.add(bottleneck,train_loss)\n",
        "  validation_loss_bottleneck.add(bottleneck,validation_loss)\n",
        "  dic_MSE[bottleneck]= [test_MSE.item(),list_MSE_validation[-1].item()]"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bottleneck :1\n",
            "Train epoch [1/1], loss:-0.2360, validation loss = -0.2727, MSE:0.87\n",
            "Bottleneck :5\n",
            "Train epoch [1/1], loss:-0.6885, validation loss = -0.6831, MSE:0.75\n",
            "Bottleneck :9\n",
            "Train epoch [1/1], loss:-0.8091, validation loss = -0.8010, MSE:0.71\n",
            "Bottleneck :13\n",
            "Train epoch [1/1], loss:-0.8573, validation loss = -0.8629, MSE:0.70\n",
            "Bottleneck :17\n",
            "Train epoch [1/1], loss:-0.8499, validation loss = -0.8406, MSE:0.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9U4c-MGWtg",
        "colab_type": "text"
      },
      "source": [
        "Plot the Loss and the MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33XfpNMJr7Wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "negpfwPv6J7U",
        "colab_type": "code",
        "outputId": "649f156a-7693-4ffa-a865-28f4b011cf20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "bottleneck = 15\n",
        "model = Autoencoder(bottleneck).cuda()\n",
        "model.to(hparams['device'])\n",
        "list_MSE_validation = []\n",
        "list_MSE_test = []\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "list_test_loss = []\n",
        "criterion_MSE = nn.MSELoss()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer =  optim.Adam(model.parameters(), lr=hparams['learning_rate'])\n",
        "for epoch in range(hparams['num_epochs']):\n",
        "  loss_train = train_epoch(train_loader,model,optimizer,criterion,hparams)\n",
        "  val_loss,MSE_validation = test_epoch(validation_loader,model,hparams)\n",
        "  test_loss,MSE_test = test_epoch(test_loader,model,hparams)\n",
        "  train_loss.append(loss_train)\n",
        "  validation_loss.append(val_loss)\n",
        "  list_test_loss.append(test_loss)\n",
        "  list_MSE_validation.append(MSE_validation)\n",
        "  list_MSE_test.append(MSE_test)\n",
        "  print('Train epoch [{}/{}], loss:{:.4f}, validation loss = {:.4f}, MSE:{:.2f}'\n",
        "  .format(epoch+1, hparams['num_epochs'], loss_train,val_loss,MSE_validation))\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch [1/10], loss:-0.8233, validation loss = -0.8430, MSE:0.70\n",
            "Train epoch [2/10], loss:-1.4962, validation loss = -1.4922, MSE:0.61\n",
            "Train epoch [3/10], loss:-2.1166, validation loss = -2.0590, MSE:0.57\n",
            "Train epoch [4/10], loss:-2.7251, validation loss = -2.6475, MSE:0.56\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-1188b040bdf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMSE_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMSE_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-4d5c55c810ce>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, optimizer, criterion, hparams)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mavg_loss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mavg_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z2eM85OkyRz",
        "colab_type": "code",
        "outputId": "261718f5-3450-488f-83bd-57de29489152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('BCEloss')\n",
        "plt.plot(train_loss,'r', label='train loss' )\n",
        "plt.plot(validation_loss,'b',label='validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f007f6f6860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAHgCAYAAAACM9GVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW95HDZbou3P",
        "colab_type": "text"
      },
      "source": [
        "##Table of the differents MSE##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0eJOldzpFx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "01cc28b6-2f52-49db-ffd4-3e6bfcdba09e"
      },
      "source": [
        "data = {\"Bottleneck\":[\"Test MSE\",\"Validation MSE\"]}\n",
        "data.update(dic_MSE)\n",
        "df = pd.DataFrame(data)\n",
        "df = df.groupby('Bottleneck')\n",
        "df.first()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>5</th>\n",
              "      <th>9</th>\n",
              "      <th>13</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bottleneck</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Test MSE</th>\n",
              "      <td>0.881309</td>\n",
              "      <td>0.753182</td>\n",
              "      <td>0.716474</td>\n",
              "      <td>0.703849</td>\n",
              "      <td>0.704460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Validation MSE</th>\n",
              "      <td>0.874880</td>\n",
              "      <td>0.748279</td>\n",
              "      <td>0.710395</td>\n",
              "      <td>0.697882</td>\n",
              "      <td>0.699037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      1         5         9         13        17\n",
              "Bottleneck                                                      \n",
              "Test MSE        0.881309  0.753182  0.716474  0.703849  0.704460\n",
              "Validation MSE  0.874880  0.748279  0.710395  0.697882  0.699037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXDCWQFSqV1-",
        "colab_type": "text"
      },
      "source": [
        "Display of 5 random images and the ouput of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaiwCPcbqsPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take 5 random images\n",
        "random_set_loader = torch.utils.data.DataLoader(\n",
        "     mnist_testset,\n",
        "    batch_size=5, \n",
        "    shuffle=True)\n",
        "dataiter = iter(random_set_loader)\n",
        "images,_ =dataiter.next()\n",
        "images = images.cuda()\n",
        "output = model(images)\n",
        "images = images.cpu().detach().numpy()\n",
        "output = output.cpu().detach().numpy()\n",
        "fig, axes = plt.subplots(nrows=2,ncols=5,sharex=True,sharey=True,figsize=(25,4\n",
        "))  \n",
        "for images, row in zip([images, output],axes):\n",
        "  for img,ax in zip(images,row):\n",
        "    ax.imshow(np.squeeze(img), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7srcwHlp_MNl",
        "colab_type": "text"
      },
      "source": [
        "**Generate 5 new images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsUkKTwPBBwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in range(5):\n",
        "nb_images = 5\n",
        "rand_features = torch.randn(nb_images, bottleneck).to(hparams['device']) \n",
        "output = model.decoder(rand_features)\n",
        "#Visualisation\n",
        "output = output.cpu().detach().numpy()\n",
        "images_width = 28\n",
        "fig, axes = plt.subplots(nrows=1,ncols=5,sharex=True,sharey=True,figsize=(25,4))\n",
        "decoded_images = output[:nb_images]  \n",
        "for ax, img in zip(axes, decoded_images):\n",
        "    ax.imshow(np.squeeze(img), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swhbaAJcdVh2",
        "colab_type": "text"
      },
      "source": [
        "#Exercice 2#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ImVXmujF46",
        "colab_type": "text"
      },
      "source": [
        "We take a subset of 100 images and their associates label from the MNIST training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thhTDz6pjFG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_images_subnet = 100\n",
        "[trainset,_]=torch.utils.data.random_split(mnist_trainset,[nb_images_subnet,tvdataset_length-nb_images_subnet])\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=hparams['batch_size'], \n",
        "    shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khqkApdIfVqv",
        "colab_type": "text"
      },
      "source": [
        "We first take the layers of the encoder part of the  model autoencoder. We take the one with a bottleneck of length 15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2vkIG0PdYJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_pretrain = model.encoder \n",
        "encoder_pretrain.eval()\n",
        "encoder_pretrain.to(hparams['device'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzxwhWz3li9x",
        "colab_type": "text"
      },
      "source": [
        "We create the classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myOiDVjwmvtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bottleneck = 15\n",
        "class Classification(nn.Module):\n",
        "  def __init__(self,endoder):\n",
        "    super().__init__()\n",
        "    self.layers = endoder\n",
        "    #fully connected layers\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(bottleneck,10),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.layers(x)\n",
        "    x= self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuogcDR2oMIU",
        "colab_type": "text"
      },
      "source": [
        "Training with the previous weights. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhFbZABsoslF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for layer in list(model_classifier.layers):\n",
        "#  for param in layer.parameters():\n",
        "#    param.require_grad = False    #Freeze layers of the encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbQVpxWy_yeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_predictions(predicted_batch, label_batch):\n",
        "  pred = predicted_batch.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "  acum = pred.eq(label_batch.view_as(pred)).sum().item()\n",
        "  return acum\n",
        "\n",
        "def train_epoch(train_loader, network, optimizer, criterion, hparams):\n",
        "  # Activate the train=True flag inside the model\n",
        "  network.train()\n",
        "  device = hparams['device']\n",
        "  avg_loss = None\n",
        "  avg_weight = 0.1\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = network(data)\n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      if avg_loss:\n",
        "        avg_loss = avg_weight * loss.item() + (1 - avg_weight) * avg_loss\n",
        "      else:\n",
        "        avg_loss = loss.item()\n",
        "      optimizer.step()\n",
        "      if batch_idx % hparams['log_interval'] == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "              100. * batch_idx / len(train_loader), loss.item()))\n",
        "  return avg_loss\n",
        "def test_epoch(test_loader, network, hparams):\n",
        "    network.eval()\n",
        "    device = hparams['device']\n",
        "    test_loss = 0\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = network(data)\n",
        "            #test_loss += criterion(output, target,reduction='sum').item() # sum up batch loss   eduction='sum'\n",
        "            # compute number of correct predictions in the batch\n",
        "            acc += correct_predictions(output, target)\n",
        "    # Average acc across all correct predictions batches now\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = 100. * acc / len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, acc, len(test_loader.dataset), test_acc,\n",
        "        ))\n",
        "    return test_loss, test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL5CyLd1Ir7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch(model_):  \n",
        "    tr_losses = []\n",
        "    te_losses = []\n",
        "    te_accs = []\n",
        "    model_.to(hparams['device'])\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=hparams['learning_rate'])\n",
        "    criterion = F.nll_loss\n",
        "    for epoch in range(1, hparams['num_epochs'] + 50):\n",
        "      print('Epoch {}'.format(epoch))\n",
        "      tr_losses.append(train_epoch(train_loader, model_, optimizer, criterion, hparams))\n",
        "      te_loss, te_acc = test_epoch(test_loader, model_, hparams)\n",
        "      te_losses.append(te_loss)\n",
        "      te_accs.append(te_acc)   \n",
        "    return te_accs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkuUBNytbuWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_classifier = Classification(encoder_pretrain)\n",
        "te_accs=epoch(model_classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clvxyd1dW6ck",
        "colab_type": "text"
      },
      "source": [
        "Model Train from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAl4W7jzW-K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier_scratch(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.bottleneck = 15\n",
        "    self.layers = Encoder(self.bottleneck)\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.bottleneck,10),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x= self.layers(x)\n",
        "    x= self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9XO-xl_ZM8l",
        "colab_type": "text"
      },
      "source": [
        "Train the model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLJPz3qNZTqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network_scratch = Classifier_scratch()\n",
        "te_accs_scratch = epoch(network_scratch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66fb84XHd1UG",
        "colab_type": "text"
      },
      "source": [
        "Plot all the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZPHQsD9e5O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "#hide axes\n",
        "fig.patch.set_visible(False)\n",
        "ax.axis('off')\n",
        "ax.axis('tight')\n",
        "data = {'Accuracy Train model %':te_accs,'Accuracy Model from scratch %':te_accs_scratch}\n",
        "df = pd.DataFrame(data)\n",
        "ax.table(cellText=df.values, colLabels=df.columns, loc='center')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}